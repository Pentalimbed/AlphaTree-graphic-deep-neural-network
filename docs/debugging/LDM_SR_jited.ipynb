{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDM_SR_jited.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_VZUcnVveXny",
        "115Y_TyxYkbk",
        "bJsLMq9pplwM",
        "O6t9w7xdHv6D"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Common\n",
        "Always run this, when start/restart the runtime"
      ],
      "metadata": {
        "id": "_VZUcnVveXny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from scipy import integrate\n",
        "from threading import Thread\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm.auto import trange, tqdm\n",
        "\n",
        "def append_dims(x, target_dims):\n",
        "    \"\"\"Appends dimensions to the end of a tensor until it has target_dims dimensions.\"\"\"\n",
        "    dims_to_append = target_dims - x.ndim\n",
        "    if dims_to_append < 0:\n",
        "        raise ValueError(f'input has {x.ndim} dims but target_dims is {target_dims}, which is less')\n",
        "    return x[(...,) + (None,) * dims_to_append]\n",
        "\n",
        "\n",
        "def append_zero(x):\n",
        "    return torch.cat([x, x.new_zeros([1])])\n",
        "\n",
        "\n",
        "def get_sigmas_karras(n, sigma_min, sigma_max, rho=7., device='cuda'):\n",
        "    \"\"\"Constructs the noise schedule of Karras et al. (2022).\"\"\"\n",
        "    ramp = torch.linspace(0, 1, n,device=device)\n",
        "    min_inv_rho = sigma_min ** (1 / rho)\n",
        "    max_inv_rho = sigma_max ** (1 / rho)\n",
        "    sigmas = (max_inv_rho + ramp * (min_inv_rho - max_inv_rho)) ** rho\n",
        "    return append_zero(sigmas).to(device)\n",
        "\n",
        "\n",
        "def get_sigmas_exponential(n, sigma_min, sigma_max, device='cpu'):\n",
        "    \"\"\"Constructs an exponential noise schedule.\"\"\"\n",
        "    sigmas = torch.linspace(math.log(sigma_max), math.log(sigma_min), n, device=device).exp()\n",
        "    return append_zero(sigmas)\n",
        "\n",
        "\n",
        "def get_sigmas_vp(n, beta_d=19.9, beta_min=0.1, eps_s=1e-3, device='cpu'):\n",
        "    \"\"\"Constructs a continuous VP noise schedule.\"\"\"\n",
        "    t = torch.linspace(1, eps_s, n, device=device)\n",
        "    sigmas = torch.sqrt(torch.exp(beta_d * t ** 2 / 2 + beta_min * t) - 1)\n",
        "    return append_zero(sigmas)\n",
        "\n",
        "\n",
        "def to_d(x, sigma, denoised):\n",
        "    \"\"\"Converts a denoiser output to a Karras ODE derivative.\"\"\"\n",
        "    return (x - denoised) / append_dims(sigma, x.ndim)\n",
        "\n",
        "\n",
        "def get_ancestral_step(sigma_from, sigma_to):\n",
        "    \"\"\"Calculates the noise level (sigma_down) to step down to and the amount\n",
        "    of noise to add (sigma_up) when doing an ancestral sampling step.\"\"\"\n",
        "    sigma_up = (sigma_to ** 2 * (sigma_from ** 2 - sigma_to ** 2) / sigma_from ** 2) ** 0.5\n",
        "    sigma_down = (sigma_to ** 2 - sigma_up ** 2) ** 0.5\n",
        "    return sigma_down, sigma_up\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_euler(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0., s_tmax=float('inf'), s_noise=1.):\n",
        "    \"\"\"Implements Algorithm 2 (Euler steps) from Karras et al. (2022).\"\"\"\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        gamma = min(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\n",
        "        eps = torch.randn_like(x) * s_noise\n",
        "        sigma_hat = sigmas[i] * (gamma + 1)\n",
        "        if gamma > 0:\n",
        "            x = x + eps * (sigma_hat ** 2 - sigmas[i] ** 2) ** 0.5\n",
        "        denoised = model( i, hlog0.revpre(x,sigmas,i), sigma_hat * s_in, **extra_args)\n",
        "        d = to_d(x, sigma_hat, denoised)\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'denoised': denoised})\n",
        "        dt = sigmas[i + 1] - sigma_hat\n",
        "        # Euler method\n",
        "        x = x + d * dt\n",
        "    return x\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None):\n",
        "    \"\"\"Ancestral sampling with Euler method steps.\"\"\"\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        denoised = model(  i,  hlog0.revpre(x,sigmas,i), sigmas[i] * s_in, **extra_args)\n",
        "        sigma_down, sigma_up = get_ancestral_step(sigmas[i], sigmas[i + 1])\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas[i], 'denoised': denoised})\n",
        "        d = to_d(x, sigmas[i], denoised)\n",
        "        # Euler method\n",
        "        dt = sigma_down - sigmas[i]\n",
        "        x = x + d * dt\n",
        "        x = x + torch.randn_like(x) * sigma_up\n",
        "    return x\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_heun(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0., s_tmax=float('inf'), s_noise=1.):\n",
        "    \"\"\"Implements Algorithm 2 (Heun steps) from Karras et al. (2022).\"\"\"\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        gamma = min(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\n",
        "        eps = torch.randn_like(x) * s_noise\n",
        "        sigma_hat = sigmas[i] * (gamma + 1)\n",
        "        if gamma > 0:\n",
        "            x = x + eps * (sigma_hat ** 2 - sigmas[i] ** 2) ** 0.5\n",
        "        denoised = model(  i,  hlog0.revpre(x,sigmas,i), sigma_hat * s_in, **extra_args)\n",
        "        d = to_d(x, sigma_hat, denoised)\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'denoised': denoised})\n",
        "        dt = sigmas[i + 1] - sigma_hat\n",
        "        if sigmas[i + 1] == 0:\n",
        "            # Euler method\n",
        "            x = x + d * dt\n",
        "        else:\n",
        "            # Heun's method\n",
        "            x_2 = x + d * dt\n",
        "            denoised_2 = model(i, x_2, sigmas[i + 1] * s_in, **extra_args)\n",
        "            d_2 = to_d(x_2, sigmas[i + 1], denoised_2)\n",
        "            d_prime = (d + d_2) / 2\n",
        "            x = x + d_prime * dt\n",
        "    return x\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_dpm_2(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0., s_tmax=float('inf'), s_noise=1.):\n",
        "    \"\"\"A sampler inspired by DPM-Solver-2 and Algorithm 2 from Karras et al. (2022).\"\"\"\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        gamma = min(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\n",
        "        eps = torch.randn_like(x) * s_noise\n",
        "        sigma_hat = sigmas[i] * (gamma + 1)\n",
        "        if gamma > 0:\n",
        "            x = x + eps * (sigma_hat ** 2 - sigmas[i] ** 2) ** 0.5\n",
        "        denoised = model(  i,  hlog0.revpre(x,sigmas,i), sigma_hat * s_in, **extra_args)\n",
        "        d = to_d(x, sigma_hat, denoised)\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'denoised': denoised})\n",
        "        # Midpoint method, where the midpoint is chosen according to a rho=3 Karras schedule\n",
        "        sigma_mid = ((sigma_hat ** (1 / 3) + sigmas[i + 1] ** (1 / 3)) / 2) ** 3\n",
        "        dt_1 = sigma_mid - sigma_hat\n",
        "        dt_2 = sigmas[i + 1] - sigma_hat\n",
        "        x_2 = x + d * dt_1\n",
        "        denoised_2 = model(i,x_2, sigma_mid * s_in, **extra_args)\n",
        "        d_2 = to_d(x_2, sigma_mid, denoised_2)\n",
        "        x = x + d_2 * dt_2\n",
        "    return x\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_dpm_2_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None):\n",
        "    \"\"\"Ancestral sampling with DPM-Solver inspired second-order steps.\"\"\"\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        denoised = model(  i,  hlog0.revpre(x,sigmas,i), sigmas[i] * s_in, **extra_args)\n",
        "        sigma_down, sigma_up = get_ancestral_step(sigmas[i], sigmas[i + 1])\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas[i], 'denoised': denoised})\n",
        "        d = to_d(x, sigmas[i], denoised)\n",
        "        # Midpoint method, where the midpoint is chosen according to a rho=3 Karras schedule\n",
        "        sigma_mid = ((sigmas[i] ** (1 / 3) + sigma_down ** (1 / 3)) / 2) ** 3\n",
        "        dt_1 = sigma_mid - sigmas[i]\n",
        "        dt_2 = sigma_down - sigmas[i]\n",
        "        x_2 = x + d * dt_1\n",
        "        denoised_2 = model(i, x_2, sigma_mid * s_in, **extra_args)\n",
        "        d_2 = to_d(x_2, sigma_mid, denoised_2)\n",
        "        x = x + d_2 * dt_2\n",
        "        x = x + torch.randn_like(x) * sigma_up\n",
        "    return x\n",
        "\n",
        "\n",
        "def linear_multistep_coeff(order, t, i, j):\n",
        "    if order - 1 > i:\n",
        "        raise ValueError(f'Order {order} too high for step {i}')\n",
        "    def fn(tau):\n",
        "        prod = 1.\n",
        "        for k in range(order):\n",
        "            if j == k:\n",
        "                continue\n",
        "            prod *= (tau - t[i - k]) / (t[i - j] - t[i - k])\n",
        "        return prod\n",
        "    return integrate.quad(fn, t[i], t[i + 1], epsrel=1e-4)[0]\n",
        "\n",
        "class area4:\n",
        "  def __init__(self,tenz):\n",
        "    jlist=[self.cxxxx,self.cWxxx,self.cxExx,self.cWExx,\n",
        "        self.cxxNx,self.cWxNx,self.cxENx,self.cWENx,\n",
        "        self.cxxxS,self.cWxxS,self.cxExS,self.cWExS,\n",
        "        self.cxxNS,self.cWxNS,self.cxENS,self.cWENS]\n",
        "    skey=list(tenz.shape)\n",
        "    self.O_h=skey[2]\n",
        "    self.O_w=skey[3]\n",
        "    self.Wlap,self.Wpad,self.Wall=calcUnCrop4(0)\n",
        "    self.Elap,self.Epad,self.Eall=calcUnCrop4(1)\n",
        "    self.Nlap,self.Npad,self.Nall=calcUnCrop4(2)\n",
        "    self.Slap,self.Spad,self.Sall=calcUnCrop4(3)\n",
        "    skey[2]=self.O_h+self.Npad+self.Spad\n",
        "    skey[3]=self.O_w+self.Wpad+self.Epad\n",
        "    self.skey=skey\n",
        "    njmp=0\n",
        "    if self.Wall > 0:\n",
        "      njmp+=1\n",
        "    if self.Eall > 0:\n",
        "      njmp+=2\n",
        "    if self.Nall > 0:\n",
        "      njmp+=4\n",
        "    if self.Sall > 0:\n",
        "      njmp+=8\n",
        "    self.calc=jlist[njmp]\n",
        "    hlog0.setWENS(self.Wlap,self.Elap,self.Nlap,self.Slap)\n",
        "\n",
        "  def getshapes(self):\n",
        "    return self.calc()\n",
        "\n",
        "  def cxxxx(self):\n",
        "    return []\n",
        "  def simpNS(self):\n",
        "    return [(0,self.Nall, 0,None, 2),(-self.Sall,None, 0,None, 3)]\n",
        "  def simpWE(self):\n",
        "    return [(0,None, 0,self.Wall ,0),(0,None, -self.Eall,None ,1)]\n",
        "  #==\n",
        "  def cWxxx(self):\n",
        "    Npad=self.Npad\n",
        "    return [(Npad,self.O_h+Npad,0,self.Wall,4)]\n",
        "  def cxExx(self):\n",
        "    Npad=self.Npad\n",
        "    return [(Npad,self.O_h+Npad,-self.Eall,None,5)]\n",
        "  def cxxNx(self):\n",
        "    Wpad=self.Wpad\n",
        "    return [(0,self.Nall,self.Wpad,self.O_w+Wpad,6)]\n",
        "  def cxxxS(self):\n",
        "    Wpad=self.Wpad\n",
        "    return [(-self.Sall,None,self.Wpad,self.O_w+Wpad,7)]\n",
        "  #==\n",
        "  def cxENS(self):\n",
        "    Npad=self.Npad\n",
        "    return [(Npad,self.O_h+Npad,-self.Eall,None,1)]+self.simpNS()\n",
        "  def cWxNS(self):\n",
        "    Npad=self.Npad\n",
        "    return [(Npad,self.O_h+Npad,0,self.Wall,0)]+self.simpNS()\n",
        "  def cWExS(self):\n",
        "    Wpad=self.Wpad\n",
        "    return [(-self.Sall,None,self.Wpad,self.O_w+Wpad,3)]+self.simpWE()\n",
        "  def cWENx(self):\n",
        "    Wpad=self.Wpad\n",
        "    return [(0,self.Nall,self.Wpad,self.O_w+Wpad,2)]+self.simpWE()\n",
        "  #==\n",
        "  def cWExx(self):\n",
        "    return self.cWxxx()+self.cxExx()\n",
        "  def cxxNS(self):\n",
        "    return self.cxxNx()+self.cxxxS()\n",
        "  #==\n",
        "  def cWxNx(self):\n",
        "    if self.skey[2] > self.skey[3]: #h>w\n",
        "      return [(self.Npad,None, 0,self.Wall   ,0),(0,self.Nall, 0,None     ,2)]\n",
        "    return   [(0,self.Nall,   self.Wpad,None ,2),(0,None,    0,self.Wall  ,0)]\n",
        "  def cxENx(self):\n",
        "    if self.skey[2] > self.skey[3]:\n",
        "      return [(self.Npad,None, -self.Eall,None, 1),(0,self.Nall, 0,None,    2)]\n",
        "    return   [(0,self.Nall,  0,-self.Epad,   2),(0,None,   -self.Eall,None,1)]\n",
        "  def cWxxS(self):\n",
        "    if self.skey[2] > self.skey[3]:\n",
        "      return [(0,-self.Spad,  0,self.Wall   ,0),(-self.Sall,None, 0,None  ,3)]\n",
        "    return   [(-self.Sall,None, self.Wpad,None ,3),(0,None,     0,self.Wall,0)]\n",
        "  def cxExS(self):\n",
        "    if self.skey[2] > self.skey[3]:\n",
        "      return [(0,-self.Spad,  -self.Eall,None ,1),(-self.Sall,None,  0,None    ,3)]\n",
        "    return   [(-self.Sall,None, 0,-self.Epad,  3),(0,None,      -self.Eall,None,1)]\n",
        "  #==\n",
        "  def cWENS(self):\n",
        "    Wpad=self.Wpad\n",
        "    Npad=self.Npad\n",
        "    if self.skey[2] > self.skey[3]:\n",
        "      if Npad > self.Spad:\n",
        "        return [(-self.Sall,None, Wpad,self.O_w+Wpad,  3),(Npad,None  ,0,self.Wall,0),(Npad,None,-self.Eall,None,1)  ,(0,self.Nall,   0,None  ,2)]\n",
        "      else:\n",
        "        return [(0,self.Nall,   Wpad,self.O_w+Wpad,  2),(0,-self.Spad,0,self.Wall,0),(0,-self.Spad,-self.Eall,None,1)  ,(-self.Sall,None, 0,None  ,3)]\n",
        "    else:\n",
        "      if Wpad > self.Epad:\n",
        "        return [(Npad,self.O_h+Npad, -self.Eall,None ,1),(0,self.Nall, Wpad,None   ,2),(-self.Sall,None, Wpad,None ,3)  ,(0,None, 0,self.Wall  ,0)]\n",
        "      else:\n",
        "        return [(Npad,self.O_h+Npad, 0,self.Wall   ,0),(0,self.Nall, 0,-self.Epad ,2),(-self.Sall,None, 0,-self.Epad ,3) ,(0,None, -self.Eall,None ,1)]\n",
        "\n",
        "def arrmover(arr, itm, n):\n",
        "  if itm is None:\n",
        "    return None\n",
        "  if len(arr) == n:\n",
        "    new_itm=[None]*len(itm)\n",
        "    arr.append(new_itm)\n",
        "    return new_itm\n",
        "  return arr[n]\n",
        "\n",
        "def mulifnotnone(v,r):\n",
        "  if v is None:\n",
        "    return None\n",
        "  return int(0.5+v*r)\n",
        "\n",
        "class hlogger:\n",
        "  def __init__(self):\n",
        "    self.Arevpre = self.Arevpre0\n",
        "    self.revpre = self.revpre0\n",
        "    self.revpre_nocpy = self.revpre0\n",
        "    self.latlog_arr=[]\n",
        "    self.h_bs_arr=[]\n",
        "    self.latlog=None\n",
        "    self.h_bs=None\n",
        "    self.h_bsB=None\n",
        "    self.Wlap=None\n",
        "    self.Elap=None\n",
        "    self.Nlap=None\n",
        "    self.Slap=None\n",
        "    self.Wlap2=None\n",
        "    self.Elap2=None\n",
        "    self.Nlap2=None\n",
        "    self.Slap2=None\n",
        "    self.funclist={'0':self.Arevpre0,'logw0':self.logw0,'logw':self.logw,'loghs':self.loghs}\n",
        "    self.funclistb={'0':self.revpre0,'masking':self.revpreMSK,'1s':self.revpre1s,'log':self.revpre0_log}\n",
        "    self.funclist2=[self.revpreW,self.revpreE,self.revpreN,self.revpreS,\n",
        "            self.revpreW_nocpy,self.revpreE_nocpy,self.revpreN_nocpy,self.revpreS_nocpy]\n",
        "    self.funclist2b=[self.bW,self.bE,self.bN,self.bS]\n",
        "    self.funclist2c=[self.bWsimp,self.bEsimp,self.bNsimp,self.bSsimp]\n",
        "    self.func2Nb_cache=99\n",
        "    self.func2Nc_cache=99\n",
        "\n",
        "\n",
        "  def setWENS(self,Wlap,Elap,Nlap,Slap):\n",
        "    self.Wlap=Wlap\n",
        "    self.Elap=Elap\n",
        "    self.Nlap=Nlap\n",
        "    self.Slap=Slap\n",
        "    self.Wlap2=Wlap<<1\n",
        "    self.Elap2=Elap<<1\n",
        "    self.Nlap2=Nlap<<1\n",
        "    self.Slap2=Slap<<1\n",
        "\n",
        "  def activefuncN2x(self, nx_cache, funclist):\n",
        "    if nx_cache < 99:\n",
        "      ndm=3\n",
        "      if nx_cache < 2:\n",
        "        ndm=2\n",
        "      if self.h_bsB.size(ndm) != noise.size(ndm):\n",
        "        self.revpre = self.revpre0\n",
        "      else:\n",
        "        self.revpre=funclist[nx_cache]\n",
        "\n",
        "\n",
        "\n",
        "  def set_multinm(self,n,cur_h,dst_h,cur_w,dst_w):\n",
        "    self.latlog = arrmover(self.latlog_arr, self.latlog, n)\n",
        "    self.h_bs = arrmover(self.h_bs_arr, self.h_bs, n)\n",
        "    self.activefuncN2x(self.func2Nb_cache, self.funclist2b)\n",
        "    self.activefuncN2x(self.func2Nc_cache, self.funclist2c)\n",
        "    if n == 0:\n",
        "      self.Wlap_orig=self.Wlap\n",
        "      self.Elap_orig=self.Elap\n",
        "      self.Nlap_orig=self.Nlap\n",
        "      self.Slap_orig=self.Slap\n",
        "      self.Wlap2_orig=self.Wlap2\n",
        "      self.Elap2_orig=self.Elap2\n",
        "      self.Nlap2_orig=self.Nlap2\n",
        "      self.Slap2_orig=self.Slap2\n",
        "      \n",
        "    if cur_h != dst_h:\n",
        "      r=cur_h/dst_h\n",
        "      self.Nlap=mulifnotnone(self.Nlap_orig,r)\n",
        "      self.Nlap2=mulifnotnone(self.Nlap2_orig,r)\n",
        "      self.Slap=mulifnotnone(self.Slap_orig,r)\n",
        "      self.Slap2=mulifnotnone(self.Slap2_orig,r)\n",
        "    else:\n",
        "      self.Nlap2=self.Nlap2_orig\n",
        "      self.Slap2=self.Slap2_orig\n",
        "      self.Nlap=self.Nlap_orig\n",
        "      self.Slap=self.Slap_orig\n",
        "\n",
        "    if cur_w != dst_w:\n",
        "      r=cur_w/dst_w\n",
        "      self.Elap=mulifnotnone(self.Elap_orig,r)\n",
        "      self.Elap2=mulifnotnone(self.Elap2_orig,r)\n",
        "      self.Wlap=mulifnotnone(self.Wlap_orig,r)\n",
        "      self.Wlap2=mulifnotnone(self.Wlap2_orig,r)\n",
        "    else:\n",
        "      self.Elap2=self.Elap2_orig\n",
        "      self.Wlap2=self.Wlap2_orig\n",
        "      self.Elap=self.Elap_orig\n",
        "      self.Wlap=self.Wlap_orig\n",
        "\n",
        "\n",
        "  def setfunc(self,key):\n",
        "    self.Arevpre=self.funclist[key]\n",
        "  def setfuncb(self,key,key2='0'):\n",
        "    self.revpre=self.funclistb[key]\n",
        "    self.revpre_nocpy=self.funclistb[key2]\n",
        "  def setfuncN(self,n):\n",
        "    self.Arevpre=self.funclist2[n]\n",
        "\n",
        "  def setfuncNb(self,n,cache=False):\n",
        "    if n > 3:\n",
        "      n-=4\n",
        "    if cache:\n",
        "      self.func2Nb_cache=n\n",
        "    else:\n",
        "      self.revpre=self.funclist2b[n]\n",
        "\n",
        "  def setfuncNc(self,n,cache=False):\n",
        "    if cache:\n",
        "      self.func2Nc_cache=n\n",
        "    else:\n",
        "      self.revpre=self.funclist2c[n]\n",
        "\n",
        "  def setbsB(self,fn,lat):\n",
        "    if fn > 3:\n",
        "      fn-=4\n",
        "    if fn==-10:\n",
        "      self.h_bsB=lat\n",
        "    elif fn==-11:\n",
        "      self.h_bsB=lat[:,:,:,-self.Elap2:-self.Elap].cuda()\n",
        "    elif fn==0:\n",
        "      self.h_bsB=torch.cat([ lat[:,:,:,:-self.Wlap], self.h_bsB[:,:,:,self.Wlap:] ],dim=3)\n",
        "    elif fn==1:\n",
        "      self.h_bsB=torch.cat([ self.h_bsB[:,:,:,:-self.Elap], lat[:,:,:,self.Elap:] ],dim=3)\n",
        "    elif fn==2:\n",
        "      self.h_bsB=torch.cat([ lat[:,:,:-self.Nlap,:], self.h_bsB[:,:,self.Nlap:,:] ],dim=2)\n",
        "    elif fn==3:\n",
        "      self.h_bsB=torch.cat([ self.h_bsB[:,:,:-self.Slap,:], lat[:,:,self.Slap:,:] ],dim=2)\n",
        "\n",
        "\n",
        "  def revpre0(self,img,sigmas,t):\n",
        "    return img\n",
        "\n",
        "  def revpreMSK(self,img,sigmas,t):\n",
        "    return (revpreimg+noise * sigmas[t])*(1-zamask)+img*zamask\n",
        "\n",
        "  def revpre1s(self,img,sigmas,t):\n",
        "    return preimg+(noise*sigmas[t])\n",
        "\n",
        "  def revpre0_log(self,img,sigmas,t):\n",
        "    self.latlog.append( ((img-noise*sigmas[t])*(1+sigmas[t]*0.18215) ).cpu().numpy())\n",
        "    return img\n",
        "  def Arevpre0(self,h,d):\n",
        "    return\n",
        "  def logw0(self,h,d):\n",
        "    self.h_bs[d]=h[:,:,:,-self.Elap:].cpu()\n",
        "    return\n",
        "\n",
        "  def logw(self,h,d):\n",
        "    h[:,:,:,:self.Elap]=self.h_bs[d]\n",
        "    self.logw0(h,d)\n",
        "    return\n",
        "  def loghs(self,h,d):\n",
        "    self.h_bs[d]=h.cpu()\n",
        "    return\n",
        "  def revpreW(self,h,d):\n",
        "    hbz=self.h_bs[d]\n",
        "    h[:,:,:,-self.Wlap:]=hbz[:,:,:,:self.Wlap]\n",
        "    self.h_bs[d]=torch.cat([ h[:,:,:,:-self.Wlap].cpu(), hbz ],dim=3)\n",
        "    return\n",
        "  def revpreE(self,h,d):\n",
        "    hbz=self.h_bs[d]\n",
        "    h[:,:,:,:self.Elap]=hbz[:,:,:,-self.Elap:]\n",
        "    self.h_bs[d]=torch.cat([ hbz, h[:,:,:,self.Elap:].cpu() ],dim=3)\n",
        "    return\n",
        "  def revpreN(self,h,d):\n",
        "    hbz=self.h_bs[d]\n",
        "    h[:,:,-self.Nlap:,:]=hbz[:,:,:self.Nlap,:]\n",
        "    self.h_bs[d]=torch.cat([ h[:,:,:-self.Nlap,:].cpu(), hbz ],dim=2)\n",
        "    return\n",
        "  def revpreS(self,h,d):\n",
        "    hbz=self.h_bs[d]\n",
        "    h[:,:,:self.Slap,:]=hbz[:,:,-self.Slap:,:]\n",
        "    self.h_bs[d]=torch.cat([ hbz,h[:,:,self.Slap:,:].cpu() ],dim=2)\n",
        "    return\n",
        "\n",
        "  def revpreW_nocpy(self,h,d):\n",
        "    h[:,:,:,-self.Wlap:]=self.h_bs[d][:,:,:,:self.Wlap]\n",
        "    return\n",
        "  def revpreE_nocpy(self,h,d):\n",
        "    h[:,:,:,:self.Elap]=self.h_bs[d][:,:,:,-self.Elap:]\n",
        "    return\n",
        "  def revpreN_nocpy(self,h,d):\n",
        "    h[:,:,-self.Nlap:,:]=self.h_bs[d][:,:,:self.Nlap,:]\n",
        "    return\n",
        "  def revpreS_nocpy(self,h,d):\n",
        "    h[:,:,:self.Slap,:]=self.h_bs[d][:,:,-self.Slap:,:]\n",
        "    return\n",
        "\n",
        "\n",
        "  def bW(self,img,sigmas,t):\n",
        "    img[:,:,:,-self.Wlap:]=self.h_bsB[:,:,:,self.Wlap:self.Wlap2]+(noise[:,:,:,-self.Wlap:]*sigmas[t])\n",
        "    return img\n",
        "  def bE(self,img,sigmas,t):\n",
        "    img[:,:,:,:self.Elap]=self.h_bsB[:,:,:,-self.Elap2:-self.Elap]+(noise[:,:,:,:self.Elap]*sigmas[t])\n",
        "    return img\n",
        "  def bN(self,img,sigmas,t):\n",
        "    img[:,:,-self.Nlap:,:]=self.h_bsB[:,:,self.Nlap:self.Nlap2,:]+(noise[:,:,-self.Nlap:,:]*sigmas[t])\n",
        "    return img\n",
        "  def bS(self,img,sigmas,t):\n",
        "    img[:,:,:self.Slap,:]=self.h_bsB[:,:,-self.Slap2:-self.Slap,:]+(noise[:,:,:self.Slap,:]*sigmas[t])\n",
        "    return img\n",
        "\n",
        "  def bWsimp(self,img,sigmas,t):\n",
        "    img[:,:,:,-self.Wlap:]=self.h_bsB+(noise[:,:,:,-self.Wlap:]*sigmas[t])\n",
        "    return img\n",
        "  def bEsimp(self,img,sigmas,t):\n",
        "    img[:,:,:,:self.Elap]=self.h_bsB+(noise[:,:,:,:self.Elap]*sigmas[t])\n",
        "    return img\n",
        "  def bNsimp(self,img,sigmas,t):\n",
        "    img[:,:,-self.Nlap:,:]=self.h_bsB+(noise[:,:,-self.Nlap:,:]*sigmas[t])\n",
        "    return img\n",
        "  def bSsimp(self,img,sigmas,t):\n",
        "    img[:,:,:self.Slap,:]=self.h_bsB+(noise[:,:,:self.Slap,:]*sigmas[t])\n",
        "    return img\n",
        "\n",
        "hlog0=hlogger()\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_lms(model, x, sigmas, extra_args=None, callback=None, disable=None, order=4):\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    sigmas_cpu = sigmas.detach().cpu().numpy()\n",
        "    ds = []\n",
        "    for i in trange(len(sigmas) - 1, disable=disable):\n",
        "        denoised = model(  i,  hlog0.revpre(x,sigmas,i) , sigmas[i] * s_in, **extra_args)\n",
        "        d = to_d(x, sigmas[i], denoised)\n",
        "        ds.append(d)\n",
        "        if len(ds) > order:\n",
        "            ds.pop(0)\n",
        "        if callback is not None:\n",
        "            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas[i], 'denoised': denoised})\n",
        "        cur_order = min(i + 1, order)\n",
        "        coeffs = [linear_multistep_coeff(cur_order, sigmas_cpu, i, j) for j in range(cur_order)]\n",
        "        x = x + sum(coeff * d for coeff, d in zip(coeffs, reversed(ds)))\n",
        "    return x\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def log_likelihood(model, x, sigma_min, sigma_max, extra_args=None, atol=1e-4, rtol=1e-4):\n",
        "    extra_args = {} if extra_args is None else extra_args\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    v = torch.randint_like(x, 2) * 2 - 1\n",
        "    fevals = 0\n",
        "    def ode_fn(sigma, x):\n",
        "        nonlocal fevals\n",
        "        with torch.enable_grad():\n",
        "            x = x[0].detach().requires_grad_()\n",
        "            denoised = model(x, sigma * s_in, **extra_args)\n",
        "            d = to_d(x, sigma, denoised)\n",
        "            fevals += 1\n",
        "            grad = torch.autograd.grad((d * v).sum(), x)[0]\n",
        "            d_ll = (v * grad).flatten(1).sum(1)\n",
        "        return d.detach(), d_ll\n",
        "    x_min = x, x.new_zeros([x.shape[0]])\n",
        "    t = x.new_tensor([sigma_min, sigma_max])\n",
        "    sol = odeint(ode_fn, x_min, t, atol=atol, rtol=rtol, method='dopri5')\n",
        "    latent, delta_ll = sol[0][-1], sol[1][-1]\n",
        "    ll_prior = torch.distributions.Normal(0, sigma_max).log_prob(latent).flatten(1).sum(1)\n",
        "    return ll_prior + delta_ll, {'fevals': fevals}\n",
        "\n",
        "\n",
        "\n",
        "class DiscreteSchedule(nn.Module):\n",
        "    \"\"\"A mapping between continuous noise levels (sigmas) and a list of discrete noise\n",
        "    levels.\"\"\"\n",
        "\n",
        "    def __init__(self, sigmas, quantize):\n",
        "        super().__init__()\n",
        "        self.register_buffer('sigmas', sigmas)\n",
        "        self.quantize = quantize\n",
        "\n",
        "    def get_sigmas(self, n=None):\n",
        "        if n is None:\n",
        "            return append_zero(self.sigmas.flip(0))\n",
        "        t_max = len(self.sigmas) - 1\n",
        "        t = torch.linspace(t_max, 0, n, device=self.sigmas.device)\n",
        "        return append_zero(self.t_to_sigma(t))\n",
        "\n",
        "    def sigma_to_t(self, sigma, quantize=None):\n",
        "        quantize = self.quantize if quantize is None else quantize\n",
        "        \n",
        "        dists = torch.abs(sigma - self.sigmas[:, None])\n",
        "        if quantize:\n",
        "            return torch.argmin(dists, dim=0).view(sigma.shape)\n",
        "        low_idx, high_idx = torch.sort(torch.topk(dists, dim=0, k=2, largest=False).indices, dim=0)[0]\n",
        "        low, high = self.sigmas[low_idx], self.sigmas[high_idx]\n",
        "        w = (low - sigma) / (low - high)\n",
        "        w = w.clamp(0, 1)\n",
        "        t = (1 - w) * low_idx + w * high_idx\n",
        "        return t.view(sigma.shape)\n",
        "\n",
        "    def t_to_sigma(self, t):\n",
        "        t = t.float()\n",
        "        low_idx, high_idx, w = t.floor().long(), t.ceil().long(), t.frac()\n",
        "        return (1 - w) * self.sigmas[low_idx] + w * self.sigmas[high_idx]\n",
        "\n",
        "\n",
        "class DiscreteEpsDDPMDenoiser(DiscreteSchedule):\n",
        "    \"\"\"A wrapper for discrete schedule DDPM models that output eps (the predicted\n",
        "    noise).\"\"\"\n",
        "\n",
        "    def __init__(self, model, alphas_cumprod, quantize):\n",
        "        super().__init__(((1 - alphas_cumprod) / alphas_cumprod) ** 0.5, quantize)\n",
        "        self.inner_model = model\n",
        "        self.sigma_data = 1.\n",
        "\n",
        "    def get_scalings(self, sigma):\n",
        "        c_out = -sigma\n",
        "        c_in = 1 / (sigma ** 2 + self.sigma_data ** 2) ** 0.5\n",
        "        return c_out, c_in\n",
        "\n",
        "    def get_eps(self, *args, **kwargs):\n",
        "        return self.inner_model(*args, **kwargs)\n",
        "\n",
        "    def loss(self, input, noise, sigma, **kwargs):\n",
        "        c_out, c_in = [append_dims(x, input.ndim) for x in self.get_scalings(sigma)]\n",
        "        noised_input = input + noise * append_dims(sigma, input.ndim)\n",
        "        eps = self.get_eps(noised_input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
        "        return (eps - noise).pow(2).flatten(1).mean(1)\n",
        "\n",
        "    def forward(self, input, sigma, **kwargs):\n",
        "        c_out, c_in = [append_dims(x, input.ndim) for x in self.get_scalings(sigma)]\n",
        "        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
        "        return input + eps * c_out\n",
        "\n",
        "\n",
        "\n",
        "def make_ddim_timesteps(num_ddim_timesteps, num_ddpm_timesteps):\n",
        "    c = num_ddpm_timesteps // num_ddim_timesteps\n",
        "    ddim_timesteps = np.asarray(list(range(0, num_ddpm_timesteps, c)))\n",
        "\n",
        "    # add one to get the final alpha values right (the ones from first scale to data during sampling)\n",
        "    steps_out = ddim_timesteps + 1\n",
        "\n",
        "    return steps_out\n",
        "\n",
        "\n",
        "def make_ddim_sampling_parameters(alphacums, ddim_timesteps, eta):\n",
        "    # select alphas for computing the variance schedule\n",
        "    alphas = alphacums[ddim_timesteps]\n",
        "    alphas_prev = np.asarray([alphacums[0]] + alphacums[ddim_timesteps[:-1]].tolist())\n",
        "\n",
        "    # according the the formula provided in https://arxiv.org/abs/2010.02502\n",
        "    sigmas = eta * np.sqrt((1 - alphas_prev) / (1 - alphas) * (1 - alphas / alphas_prev))\n",
        "\n",
        "    return sigmas, alphas, alphas_prev\n",
        "\n",
        "def makerng():\n",
        "  global seed\n",
        "  if seed == 0:\n",
        "    seed=random.randint(0, 2**32)\n",
        "    print('random seed=')\n",
        "    print(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "def dlpromptexample():\n",
        "  !wget https://github.com/TabuaTambalam/DalleWebms/releases/download/0.1/pexmp.7z\n",
        "  !7z x pexmp.7z\n",
        "  \n",
        "\n",
        "def mkmodel_state_dict():\n",
        "  try:\n",
        "    import jkt\n",
        "  except:\n",
        "    !wget https://raw.githubusercontent.com/TabuaTambalam/DalleWebms/main/docs/sd/jkt.py\n",
        "    import jkt\n",
        "  \n",
        "  difjit=[diffusion_emb,diffusion_mid,diffusion_out]\n",
        "  model_state_dict = {}\n",
        "  jna1=jkt.nam1\n",
        "  for i in range(3):\n",
        "    sd=difjit[i].state_dict()\n",
        "    jna2=jkt.nam2[i]\n",
        "    for k in sd:\n",
        "      uwa=sd[k]\n",
        "      if 'pnnx' in k:\n",
        "        model_state_dict[jna2[k]]=uwa\n",
        "      else:\n",
        "        model_state_dict[jna1[k]]=uwa\n",
        "  return model_state_dict\n",
        "\n",
        "\n",
        "def procLat(lat):\n",
        "  if lat.dim() == 3:\n",
        "    return [lat.unsqueeze(0)],1\n",
        "  nbat=lat.size(0)\n",
        "  if nbat > 1:\n",
        "    ret=[None]*nbat\n",
        "    for i in range(nbat):\n",
        "      ret[i]=lat[i].unsqueeze(0)\n",
        "    return ret, nbat\n",
        "  return [lat],1\n",
        "\n",
        "\n",
        "SDlatDEC=None\n",
        "def latdec(fna,scale=5.5):\n",
        "  global SDlatDEC\n",
        "  if SDlatDEC is None:\n",
        "    if not os.path.isfile('autoencoder_pnnx.pt'):\n",
        "      !wget https://huggingface.co/Larvik/sd470k/resolve/main/autoencoder_pnnx.pt\n",
        "    SDlatDEC=torch.jit.load('autoencoder_pnnx.pt').cuda()\n",
        "  lat,l =procLat(torch.tensor(np.load(fna)).cuda())\n",
        "  for i in range(l):\n",
        "    lat[i]=SDlatDEC(lat[i]*scale)[0]\n",
        "  return lat\n",
        "\n",
        "def latdec2(fna,scale=5.5):\n",
        "  global SDlatDEC\n",
        "  if SDlatDEC is None:\n",
        "    if not os.path.isfile('autoencoder_pnnx.pt'):\n",
        "      !wget https://huggingface.co/Larvik/sd470k/resolve/main/autoencoder_pnnx.pt\n",
        "    SDlatDEC=torch.jit.load('autoencoder_pnnx.pt').cuda()\n",
        "  lat,l =procLat(torch.tensor(fna).cuda())\n",
        "  for i in range(l):\n",
        "    lat[i]=SDlatDEC(lat[i]*scale)[0]\n",
        "  return lat\n",
        "\n",
        "def localhttp(root='/'):\n",
        "  global HTML\n",
        "  if not os.path.isfile('/content/sample_data/izh.txt'):\n",
        "    from IPython.core.display import HTML\n",
        "    !nohup python3 -m http.server -d {root} 8233 > /content/sample_data/izh.txt &\n",
        "\n",
        "\n",
        "def f_sampler():\n",
        "  global UseSamplr\n",
        "  if Sampler == 'euler':\n",
        "    UseSamplr = sample_euler\n",
        "  elif Sampler == 'euler_a':\n",
        "    UseSamplr = sample_euler_ancestral\n",
        "  elif Sampler == 'heun':\n",
        "    UseSamplr = sample_heun\n",
        "  elif Sampler == 'dpm_2':\n",
        "    UseSamplr = sample_dpm_2\n",
        "  elif Sampler == 'dpm_2_a':\n",
        "    UseSamplr = sample_dpm_2_ancestral\n",
        "  elif Sampler == 'lms':\n",
        "    UseSamplr = sample_lms\n",
        "\n",
        "def f_sigmas():\n",
        "  if Karras:\n",
        "    return ddim_eta*get_sigmas_karras(ddim_num_steps,model_wrap.sigmas[0].item(),model_wrap.sigmas[-1].item(),rho=KarrasRho, device=cudev )\n",
        "  else:\n",
        "    return ddim_eta*model_wrap.get_sigmas(ddim_num_steps)\n",
        "\n",
        "def fixver(ver,dfsver):\n",
        "  if ver != '470k':\n",
        "    return ''\n",
        "  return dfsver\n",
        "def f_dljit(ver='470k',dfsver=''):\n",
        "  dfsver=fixver(ver,dfsver)\n",
        "  if not os.path.isfile('imgencoder_pnnx.pt'):\n",
        "    !pip install ftfy transformers omegaconf triton==2.0.0.dev20220701 einops accelerate\n",
        "    !wget https://huggingface.co/Larvik/sd{ver}/resolve/main/alphas_cumprod.npz\n",
        "    !wget https://huggingface.co/Larvik/tfmod/resolve/main/transformer_pnnx.pt\n",
        "    !wget https://huggingface.co/Larvik/sd{ver}/resolve/main/autoencoder_pnnx.pt\n",
        "    !wget https://huggingface.co/Larvik/sd{ver}/resolve/main/imgencoder_pnnx.pt\n",
        "  ver+=dfsver\n",
        "  !mkdir {ver}\n",
        "  if not os.path.isfile(ver+'/diffusion_out_pnnx.pt'):\n",
        "    !wget -P {ver}/ https://huggingface.co/Larvik/sd{ver}/resolve/main/diffusion_emb_pnnx.pt\n",
        "    !wget -P {ver}/ https://huggingface.co/Larvik/sd{ver}/resolve/main/diffusion_mid_pnnx.pt\n",
        "    !wget -P {ver}/ https://huggingface.co/Larvik/sd{ver}/resolve/main/diffusion_out_pnnx.pt\n",
        "  return ver+'/'\n",
        "\n",
        "def install_xformer():\n",
        "  print('xformer')\n",
        "  if not os.path.isfile('xformers/_C.so'):\n",
        "    !wget https://raw.githubusercontent.com/TabuaTambalam/DalleWebms/main/docs/sd/jkt.py\n",
        "    from subprocess import getoutput\n",
        "    pfix='T4'\n",
        "    gputyp=getoutput('nvidia-smi')\n",
        "    if 'P100' in gputyp:\n",
        "      pfix = 'P100'\n",
        "    elif 'V100' in gputyp:\n",
        "      pfix = 'V100'\n",
        "    elif 'A100' in gputyp:\n",
        "      pfix = 'A100'\n",
        "    !pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/{pfix}/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "    !mv /usr/local/lib/python3.7/dist-packages/xformers /content/xformers\n",
        "\n",
        "\n",
        "def get_keys_to_submodule(model):\n",
        "  keys_to_submodule = {}\n",
        "  # iterate all submodules\n",
        "  for submodule_name, submodule in model.named_modules():\n",
        "      # iterate all paramters in each submobule\n",
        "      for param_name, param in submodule.named_parameters():\n",
        "          # param_name is organized as <name>.<subname>.<subsubname> ...\n",
        "          splitted_param_name = param_name.split('.')\n",
        "          # we cannot go inside it anymore. This is the actual parameter\n",
        "          is_leaf_param = len(splitted_param_name) == 1\n",
        "          if is_leaf_param:\n",
        "              # we recreate the correct key\n",
        "              key = f\"{submodule_name}.{param_name}\"\n",
        "              # we associate this key with this submodule\n",
        "              keys_to_submodule[key] = submodule\n",
        "              \n",
        "  return keys_to_submodule\n",
        "\n",
        "inpaintwgt='UserEmb/inpaintwgt.pt'\n",
        "def wgt_to_inp(state_dict):\n",
        "  if not os.path.isfile(inpaintwgt):\n",
        "    !wget -O {inpaintwgt} https://huggingface.co/Larvik/tfmod/resolve/main/inpaintwgt.pt\n",
        "  state_dict['input_blocks.0.0.weight']=torch.cat((state_dict['input_blocks.0.0.weight'],torch.load(inpaintwgt)),dim=1)\n",
        "  return state_dict\n",
        "\n",
        "def load_state_dict_with_low_memory(model, state_dict,modifyfunc=None):\n",
        "  if modifyfunc is not None:\n",
        "    state_dict=modifyfunc(state_dict)\n",
        "  print('======hacky load======')\n",
        "  keys_to_submodule = get_keys_to_submodule(model)\n",
        "  mste=model.state_dict()\n",
        "  for key, submodule in keys_to_submodule.items():\n",
        "      # get the valye from the state_dict\n",
        "      if key in state_dict:\n",
        "        val = state_dict[key]\n",
        "      else:\n",
        "        print(key)\n",
        "        val = torch.ones(mste[key].shape, dtype= torch.float16)\n",
        "\n",
        "      param_name = key.split('.')[-1]\n",
        "      new_val = torch.nn.Parameter(val,requires_grad=False)\n",
        "      setattr(submodule, param_name, new_val)\n",
        "\n",
        "\n",
        "ldmbase='ldm'\n",
        "def init_ldm(mode,sdt_func=None):\n",
        "  global ldm_unet\n",
        "  print('orig ldm')\n",
        "  if not os.path.exists('ldm_opt'):\n",
        "    !wget https://github.com/TabuaTambalam/DalleWebms/releases/download/0.1/ldms.7z\n",
        "    !7z x ldms.7z\n",
        "  if os.path.exists(ldmbase):\n",
        "    os.unlink(ldmbase)\n",
        "  if mode==1:\n",
        "    os.symlink('ldm_opt',ldmbase)\n",
        "  elif mode==2:\n",
        "    os.symlink('ldm_xfm',ldmbase)\n",
        "  from ldm.modules.diffusionmodules.openaimodel import UNetModel\n",
        "  from accelerate import init_empty_weights\n",
        "  with init_empty_weights():\n",
        "    ldm_unet = UNetModel(\n",
        "        image_size=32,\n",
        "        in_channels=4,out_channels=4,\n",
        "            model_channels=320,\n",
        "            attention_resolutions=[4,2,1],\n",
        "            num_res_blocks=2,\n",
        "            channel_mult=[1,2,4,4],\n",
        "            num_heads=8,\n",
        "            use_spatial_transformer=True,\n",
        "            context_dim=768,\n",
        "            legacy= False).requires_grad_(False)\n",
        "  load_state_dict_with_low_memory(ldm_unet,mkmodel_state_dict(),sdt_func)\n",
        "  ldm_unet=ldm_unet.eval().to(cudev)\n",
        "\n",
        "def clamp64(n):\n",
        "  ret=n>>3\n",
        "  lez=ret&7\n",
        "  ret-=lez\n",
        "  if lez >3:\n",
        "    ret+=8\n",
        "  return ret\n",
        "\n",
        "def mk_shape():\n",
        "  shape = [n_samples, 4, clamp64(H) , clamp64(W) ]\n",
        "  nl=len(seed_size)\n",
        "  if nl> 0:\n",
        "    dst =[seed_size[-1]]+shape[2:]\n",
        "    shape[2]=clamp64(seed_size[0])\n",
        "    shape[3]=clamp64(seed_size[1])\n",
        "\n",
        "    if nl > 3:\n",
        "      ksd=seed_size[2:-1]\n",
        "      nl_2=(nl-3)//3\n",
        "      for n in range(nl_2):\n",
        "        ksd[3*n+1]=clamp64(ksd[3*n+1])\n",
        "        ksd[3*n+2]=clamp64(ksd[3*n+2])\n",
        "      shape=shape+ksd+dst\n",
        "    else:\n",
        "      shape=shape+dst\n",
        "\n",
        "  return shape\n",
        "\n",
        "class Insertor:\n",
        "  def __init__(self, string):\n",
        "    self.rpla=string+'}'\n",
        "    self.rpla_cut=len(string)+1\n",
        "    varias=mkInsertor_pstz(string)\n",
        "    ll=len(varias)\n",
        "    self.cplxlv=-1\n",
        "\n",
        "    idkole=[None]*ll\n",
        "    for n in range(ll):\n",
        "      dikv=set()\n",
        "      vaa=varias[n]\n",
        "      for u in vaa:\n",
        "        vyd=u.id\n",
        "        if vyd != 0:\n",
        "          dikv.add(vyd)\n",
        "      idkole[n]=dikv\n",
        "\n",
        "    self.ids=idkole\n",
        "    self.varias=varias\n",
        "    self.ll=ll\n",
        "    \n",
        "  def cplxLevel(self,n):\n",
        "    if n < 0:\n",
        "      cplx=0\n",
        "      if self.cplxlv>=0:\n",
        "        return self.cplxlv\n",
        "      for i in range(self.ll):\n",
        "        cplx+=self.cplxLevel(i)\n",
        "      self.cplxlv=cplx\n",
        "      return cplx\n",
        "    if self.ids[n]:\n",
        "      return len(self.ids[n])*0x1000\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# encoder\n",
        "class BERTEmbedder:\n",
        "    def __init__(self, transformer, max_length=77):\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14')\n",
        "        self.max_length = max_length\n",
        "        self.dedup=dict()\n",
        "\n",
        "        self.transformer = transformer\n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(self.transformer.state_dict()['text_model_embeddings_token_embedding.weight'])\n",
        "        self.encode = self.encode0\n",
        "\n",
        "        emptytok=self.tok('')\n",
        "        self.tok_bos, self.tok_eos = int(emptytok[0]), int(emptytok[1])\n",
        "        emptyemb=self.amb(emptytok)\n",
        "        self.emb_bos, self.emb_eos = emptyemb[0].unsqueeze(0) ,emptyemb[1]\n",
        "        \n",
        "\n",
        "    def insert(self,inz):\n",
        "      self.dedup[inz]=torch.tensor(np.fromfile('UserEmb/'+inz[1:-1]+'.bin',dtype=np.float32)).unsqueeze(0)\n",
        "\n",
        "    def insert_prompt_vars(self,inz):\n",
        "      inz='{'+inz\n",
        "      self.dedup[inz]=Insertor(inz)\n",
        "      \n",
        "    def get_empty(self):\n",
        "      return torch.cat([self.emb_bos,self.emb_eos.expand(self.max_length-1,-1) ])\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "    def tok(self, text, pad=False):\n",
        "      padstr='do_not_pad'\n",
        "      if pad:\n",
        "        padstr='max_length'\n",
        "      batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
        "                            return_overflowing_tokens=False, padding=padstr, return_tensors='pt')\n",
        "\n",
        "      return batch_encoding['input_ids'][0]\n",
        "\n",
        "    def amb(self, tokens):\n",
        "        return self.embedding(tokens)\n",
        "        \n",
        "    def mk_emb_wgt(self,unit_arr,dtal=-1):\n",
        "      if dtal < 0:\n",
        "        dtal=len(unit_arr)\n",
        "      \n",
        "      emb=[None]*(dtal+2)\n",
        "      wgt=[None]*(dtal+2)\n",
        "      txt=[]\n",
        "      emb[0]=self.emb_bos\n",
        "      wgt[0]=torch.ones(1)\n",
        "      count=self.max_length-1\n",
        "      NoWgt=True\n",
        "      for i in range(dtal):\n",
        "        emb0,wgt0=unit_arr[i].emb_wgt()\n",
        "        if wgt0[0] != 1.0:\n",
        "          NoWgt=False\n",
        "        msg = unit_arr[i].msg\n",
        "        if len(msg) > 1:\n",
        "          txt.append(msg)\n",
        "        emb[i+1]=emb0\n",
        "        wgt[i+1]=wgt0\n",
        "        count-=wgt0.size(0)\n",
        "        if count <= 0:\n",
        "          kcut=count-1\n",
        "          emb[i+1]=emb0[:kcut]\n",
        "          wgt[i+1]=wgt0[:kcut]\n",
        "          emb=emb[:i+3]\n",
        "          wgt=wgt[:i+3]\n",
        "          count=1\n",
        "          print('ignore after: '+msg)\n",
        "          break\n",
        "      \n",
        "      \n",
        "      emb[-1]=self.emb_eos.expand(count,-1)\n",
        "      if NoWgt:\n",
        "        wgt=None\n",
        "      else:\n",
        "        wgt[-1]=wgt[0].expand(count)\n",
        "      emb=torch.cat(emb)\n",
        "      \n",
        "      \n",
        "\n",
        "      #wgt=torch.cat(wgt)\n",
        "      if txt:\n",
        "        if len(txt) > 1:\n",
        "          txt=' # '.join(txt)\n",
        "        else:\n",
        "          txt=txt[0]\n",
        "      else:\n",
        "        txt=None\n",
        "      return emb, wgt, txt\n",
        "\n",
        "    def from_emb(self,emb0,wgt_arr=None,nsamp=1,cuda=True):\n",
        "      z = self.transformer( emb0.expand(1,-1,-1) )\n",
        "      if cuda:\n",
        "        z=z.cuda()\n",
        "      if wgt_arr is not None:\n",
        "        wgt=torch.cat(wgt_arr)\n",
        "        if cuda:\n",
        "          wgt=wgt.cuda()\n",
        "        ynt=z[:,0,:]\n",
        "        wgt /= torch.abs(wgt.mean())\n",
        "        z*=wgt.reshape(-1,1).expand(1,-1,-1)\n",
        "        z[:,0,:]=ynt\n",
        "      if nsamp > 1:\n",
        "        z=z.expand(nsamp,-1,-1)\n",
        "      return z\n",
        "\n",
        "    def encode0(self, text, nsamp):\n",
        "\n",
        "      if len(text) == 0:\n",
        "        return cond_getter(None)\n",
        "\n",
        "      units=pmpmtx_preproc([text],enable3d=False)[0]\n",
        "        \n",
        "      emb, wgt, txt = self.mk_emb_wgt(units,len(units))\n",
        "        \n",
        "\n",
        "      return cond_getter(emb,fast=0,nsamp=nsamp)\n",
        "\n",
        "    def encode2(self, text, nsamp):\n",
        "        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
        "                            return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        \n",
        "\n",
        "        return self.transformer( self.embedding( batch_encoding[\"input_ids\"].expand(nsamp,-1) ) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CompVisDenoiser(DiscreteEpsDDPMDenoiser):\n",
        "    \"\"\"A wrapper for CompVis diffusion models.\"\"\"\n",
        "\n",
        "    def __init__(self, model, quantize=False, device='cpu'):\n",
        "        super().__init__(model, model.alphas_cumprod, quantize=quantize)\n",
        "\n",
        "    def get_eps(self, *args, **kwargs):\n",
        "        return apply_model(*args, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nDfmCodeBase():\n",
        "  if DfmCodeBase == 'JIT':\n",
        "    return 0\n",
        "  elif DfmCodeBase == 'ldm_SaveVram':\n",
        "    return 1\n",
        "  elif DfmCodeBase == 'ldm_xformers':\n",
        "    return 2\n",
        "  return 99\n",
        "\n",
        "\n",
        "class CFGDenoiser(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.inner_model = model\n",
        "\n",
        "    def forward(self, d, x, sigma, uncond, cond, cond_scale):\n",
        "        x_in = torch.cat([x] * 2)\n",
        "        sigma_in = torch.cat([sigma] * 2)\n",
        "        cond_in = torch.cat([uncond.get(d) , cond.get(d) ])\n",
        "        uncond, cond = self.inner_model(x_in, sigma_in, cond=cond_in,d=d).chunk(2)\n",
        "        return uncond + (cond - uncond) * cond_scale\n",
        "\n",
        "\n",
        "class SRDenoiser(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.inner_model = model\n",
        "\n",
        "    def forward(self, x, sigma, cond ):\n",
        "        cond = self.inner_model(x, sigma, cond=cond)\n",
        "        return cond\n",
        "\n",
        "prevSDver=''\n",
        "prevDfmCodeBase=''\n",
        "\n",
        "class CompVisJIT():\n",
        "  def __init__(self):\n",
        "    self.alphas_cumprod=torch.tensor(alphas_cumprod,device=cudev)\n",
        "    self.apply_model=apply_model\n",
        "\n",
        "class ifeeder():\n",
        "  def __init__(self):\n",
        "    self.getn=self.get_simp\n",
        "  def get_simp(self,n):\n",
        "    return self.bs\n",
        "  def setbs(self,in_bs):\n",
        "    self.bs=in_bs\n",
        "  \n",
        "  def get_npbins(self,n):\n",
        "    return torch.tensor(np.fromfile(self.pattern%(n+1),dtype=np.float32).reshape(self.shape),device=cudev)+self.noiseadd\n",
        "\n",
        "Karras=False\n",
        "model_wrap=None"
      ],
      "metadata": {
        "id": "YzmPpU9reaMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class vinfo:\n",
        "  def __init__(self, txt):\n",
        "    self.tag=txt\n",
        "    valid=False\n",
        "    cut=-1\n",
        "    if txt[-3] == ',':\n",
        "      cut=-3\n",
        "    key=txt[:cut]\n",
        "    if key in cond_stage_model.dedup:\n",
        "      valid=True\n",
        "      self.bazkey=key\n",
        "      ActivedPromptVars[txt]=cond_stage_model.dedup[key]\n",
        "    self.valid=valid\n",
        "\n",
        "\n",
        "\n",
        "  @property\n",
        "  def baz(self):\n",
        "    return cond_stage_model.dedup[self.bazkey]\n",
        "\n",
        "  def repl(self, unit, v):\n",
        "    inzt=copy.deepcopy(self.baz.varias[v])\n",
        "    idset=self.baz.ids[v]\n",
        "    _, p_wgt, p_sta, p_end = unit.nfo()\n",
        "\n",
        "    idmap=dict()\n",
        "    procid=False\n",
        "    if idset:\n",
        "      procid=True\n",
        "      for id in idset:\n",
        "        idmap[id]=rdmIDfunc(None)\n",
        "\n",
        "    if procid:\n",
        "      for yn in inzt:\n",
        "        if yn.id == 0:\n",
        "          yn.update_sta_end(p_wgt,p_sta,p_end)\n",
        "        else:\n",
        "          yn.id=idmap[yn.id]\n",
        "          erz=yn.eraz\n",
        "          if erz:\n",
        "            nyu_erz=dict()\n",
        "            for k in erz:\n",
        "              nyu_id=idmap[k]\n",
        "              nyu_erz[nyu_id]=nyu_id\n",
        "            yn.eraz=nyu_erz\n",
        "    else:\n",
        "      for yn in inzt:\n",
        "        yn.update_sta_end(p_wgt,p_sta,p_end)\n",
        "\n",
        "       \n",
        "    return inzt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class sentUnit:\n",
        "  def __init__(self, txt,\n",
        "               fast=-1,\n",
        "               p_wgt=None,p_sta=None,p_end=None\n",
        "               ):\n",
        "\n",
        "    self.emb_wgt = self.emb_wgt0\n",
        "    self.id=0\n",
        "    usig=0\n",
        "    self.repls=dict()\n",
        "    self.eraz=None\n",
        "    if fast == 0:\n",
        "      self.sig=usig\n",
        "      self.msg, self.wgt, self.upper, self.lower =txt,p_wgt,p_sta,p_end\n",
        "      return\n",
        "    elif fast == 1:\n",
        "      self.id=rdmIDfunc(txt) #id(self)#\n",
        "      self.sig=usig\n",
        "      self.msg, self.wgt, self.upper, self.lower =txt,0,p_sta,p_end\n",
        "      #wgt as group_len\n",
        "      self.eraz=dict()\n",
        "      self.yetproc=True\n",
        "      return\n",
        "\n",
        "    \n",
        "    \n",
        "    prepand=None\n",
        "    retThis=True\n",
        "    self.real_return=[]\n",
        "    if ':' in txt:\n",
        "      usig+=0x100\n",
        "    if '+' in txt:\n",
        "      usig+=0x200\n",
        "    if ';' in txt:\n",
        "      usig+=0x400\n",
        "    if '|' in txt:\n",
        "      usig+=0x800\n",
        "    \n",
        "    self.sig=usig\n",
        "\n",
        "    if usig < 0x100:\n",
        "      self.msg, self.wgt, self.upper, self.lower = txt,p_wgt,p_sta,p_end\n",
        "      self.real_return=[self]\n",
        "    else:\n",
        "      taps=mktaps(txt,  p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      msg, self.wgt, self.upper, self.lower=taps[0]\n",
        "      if '|' in msg:\n",
        "        self.msg='^'\n",
        "        retThis=False\n",
        "        taps2=mktaps(msg, sep='|', p_wgt=self.wgt,p_sta=self.upper,p_end=self.lower)\n",
        "        for m2,w2,s2,e2 in taps2:\n",
        "          dmm=sentUnit(m2,p_wgt=w2,p_sta=s2,p_end=e2)\n",
        "          for dmm2 in get_real_return(dmm):\n",
        "            self.real_return.append(dmm2)\n",
        "      else:\n",
        "        self.msg=msg\n",
        "        self.real_return=[self]\n",
        "      \n",
        "      len_taps=len(taps)\n",
        "      \n",
        "      if len_taps > 1:\n",
        "        prepand=sentUnit('[',fast=1, p_sta=self.upper,p_end=self.lower )\n",
        "        lazt_id=prepand.id\n",
        "        eraz_arr=[prepand]\n",
        "        for i in range(1,len_taps):\n",
        "          msg,wgt_bs,sta_bs,endo_bs = taps[i]\n",
        "          edb=sentUnit(']',fast=1)\n",
        "          edb.id=lazt_id\n",
        "          pp2=sentUnit('[',fast=1,p_sta=sta_bs,p_end=endo_bs)\n",
        "          lazt_id=pp2.id\n",
        "          if '|' in msg:\n",
        "            pral=[edb,pp2]\n",
        "            taps2=mktaps(msg, sep='|', p_wgt=wgt_bs,p_sta=sta_bs,p_end=endo_bs)\n",
        "            for m2,w2,s2,e2 in taps2:\n",
        "              dmm=sentUnit(m2,p_wgt=w2,p_sta=s2,p_end=e2)\n",
        "              for dmm2 in get_real_return(dmm):\n",
        "                pral.append(dmm2) \n",
        "            self.real_return+=pral\n",
        "\n",
        "          else:\n",
        "            dmm=sentUnit(msg,p_wgt=wgt_bs, p_sta=sta_bs,p_end=endo_bs)\n",
        "            dmm_rt=get_real_return(dmm)\n",
        "            self.real_return+=[edb,pp2]+dmm_rt\n",
        "          \n",
        "          for erz in eraz_arr:\n",
        "            erz.eraz[lazt_id]=lazt_id\n",
        "          eraz_arr.append(pp2)\n",
        "        edb=sentUnit(']',fast=1)\n",
        "        edb.id=lazt_id\n",
        "        self.real_return.append(edb)\n",
        "            \n",
        "\n",
        "    if retThis:\n",
        "      self.real_return=emb_and_v(self.msg,p_wgt=self.wgt,p_sta=self.upper,p_end=self.lower)+self.real_return[1:]\n",
        "      \n",
        "   \n",
        "\n",
        "    if prepand is not None:\n",
        "      self.real_return=[prepand]+self.real_return\n",
        " \n",
        "  def nfo(self,trans_wgt=True,trans_sta=False,trans_end=False,extra=False):\n",
        "    ret_wgt=self.wgt\n",
        "    ret_sta=self.upper\n",
        "    ret_end=self.lower\n",
        "    if trans_wgt and ret_wgt is None:\n",
        "      ret_wgt=1.0\n",
        "    if trans_sta and ret_sta is None:\n",
        "      ret_sta=0\n",
        "    if trans_end and ret_end is None:\n",
        "      ret_end=1.0\n",
        "    if extra:\n",
        "      return self.msg, ret_wgt, ret_sta, ret_end,[self.wgt is None,self.upper is None,self.lower is None]\n",
        "    else:\n",
        "      return self.msg, ret_wgt, ret_sta, ret_end\n",
        "\n",
        "  def get_sig(self):\n",
        "    ret=0\n",
        "    if self.eraz:\n",
        "      ret = 0x1000\n",
        "    if self.upper is not None:\n",
        "      return ret + 0x100\n",
        "    if self.lower is not None:\n",
        "      return ret + 0x100\n",
        "    return ret\n",
        "\n",
        "  def get_realstaend(self):\n",
        "    sta=0\n",
        "    endo=t_enc\n",
        "    if self.upper is not None:\n",
        "      sta=int(self.upper*t_enc +0.5)\n",
        "    if self.lower is not None:\n",
        "      endo=int(self.lower*t_enc +0.5)\n",
        "    return sta, endo\n",
        "\n",
        "  def get_realwgt(self):\n",
        "    if self.wgt is None:\n",
        "      return 1.0\n",
        "    return self.wgt\n",
        "\n",
        "\n",
        "  def set_emb(self,n):\n",
        "    if n == 1:\n",
        "      self.tok_len=1\n",
        "      self.emb_wgt = self.emb_wgt1\n",
        "      self.fast_emb= cond_stage_model.dedup[self.msg]\n",
        "      \n",
        "\n",
        "  def emb_wgt1(self):\n",
        "    wgg=torch.ones(1)\n",
        "    if self.wgt is not None:\n",
        "      wgg*=self.wgt\n",
        "\n",
        "    return self.fast_emb, wgg\n",
        "  def emb_wgt0(self):\n",
        "    tok=cond_stage_model.tok(self.msg)[1:-1]\n",
        "    tkl=tok.size(0)\n",
        "    self.tok_len=tkl\n",
        "    wgg=torch.ones(tkl)\n",
        "    if self.wgt is not None:\n",
        "      wgg*=self.wgt\n",
        "    amb = cond_stage_model.embedding(tok)\n",
        "    return amb,wgg\n",
        "  \n",
        "  def update_sta_end(self, wgt, sta, endo):\n",
        "    if self.wgt is None:\n",
        "      self.wgt=wgt\n",
        "    if self.upper is None:\n",
        "      self.upper=sta\n",
        "    if self.lower is None:\n",
        "      self.lower=endo\n",
        "\n",
        "  def __repr__(self):\n",
        "    ret=stringlizeNfo(self)\n",
        "    if self.eraz:\n",
        "      ret+='\\n'+str(self.eraz)\n",
        "    return ret\n",
        "\n",
        "\n",
        "# arr=emb\n",
        "class cond_getter:\n",
        "  def __init__(self, arr, wgt_arr=None, reftxt=None, kndref=None, fast=-1, nsamp=1,cuda=True):\n",
        "    self.txt=[]\n",
        "    if reftxt is not None:\n",
        "      self.txt=reftxt\n",
        "\n",
        "    self.add_sta=0\n",
        "    self.d_sta=0\n",
        "    self.is_simp=True\n",
        "    self.get=self.get_simp\n",
        "    self.get_txt=self.txt_simp\n",
        "    if arr is None:\n",
        "      emb = cond_stage_model.get_empty()\n",
        "      self.arr = cond_stage_model.from_emb(emb,nsamp=nsamp,cuda=cuda)\n",
        "      return\n",
        "    if fast==0:\n",
        "      self.arr = cond_stage_model.from_emb(arr,wgt_arr=wgt_arr,nsamp=nsamp,cuda=cuda)\n",
        "      return\n",
        "    elif fast == 1:\n",
        "      self.arr=arr\n",
        "      return\n",
        "  \n",
        "    self.knd=kndref\n",
        "    self.is_simp=False\n",
        "    arr.append(arr[-1])\n",
        "    self.arr=arr\n",
        "    self.get=self.get_arr\n",
        "    self.get_txt=self.txt_arr\n",
        "      \n",
        "  def get_knd(self):\n",
        "    if self.is_simp:\n",
        "      return np.ones(t_enc,dtype=np.uint8)*0xff\n",
        "    return self.knd\n",
        "\n",
        "  def get_fullarr(self):\n",
        "    if self.is_simp:\n",
        "      return [self.arr]*t_enc\n",
        "    return self.arr\n",
        "\n",
        "\n",
        "  def get_simp(self,d):\n",
        "    return self.arr\n",
        "\n",
        "  def reset(self):\n",
        "    self.add_sta=0\n",
        "    self.d_sta=0\n",
        "\n",
        "  def txt_simp(self,d):\n",
        "    return self.txt\n",
        "  \n",
        "  def get_arr(self,d):\n",
        "    sd=d+self.add_sta\n",
        "    if self.d_sta > 1:\n",
        "      sd=int(0.5+d*self.d_sta)\n",
        "    return self.arr[sd]\n",
        "\n",
        "  def txt_arr(self,d):\n",
        "    return self.txt[d]"
      ],
      "metadata": {
        "id": "xvbB9o3b9nrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_real_return(unit):\n",
        "  grr=unit.real_return\n",
        "  del unit.real_return\n",
        "  return grr\n",
        "\n",
        "def rdmIDfunc(yd):\n",
        "  #print(yd[:2])\n",
        "  return random.randint(0, 2**32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def stringlizeNfo(src):\n",
        "  msg,wgt,sta,endo = src.nfo()\n",
        "  if wgt != 1.0:\n",
        "    msg+='+'+str(wgt)\n",
        "  sig=0\n",
        "  if sta is not None:\n",
        "    sig+=1\n",
        "  if endo is not None:\n",
        "    sig+=2\n",
        "\n",
        "  if sig == 0:\n",
        "    return msg\n",
        "  elif sig==1:\n",
        "    return msg+':'+str(int(0.5+sta*100))+':'\n",
        "  elif sig==2:\n",
        "    return msg+'::'+str(int(0.5+endo*100))\n",
        "  elif sig==3:\n",
        "    return msg+':'+str(int(0.5+sta*100))+':'+str(int(0.5+endo*100))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mkInsertor_pstz(string):\n",
        "  fna = 'UserEmb/'+string[1:]+'.txt'\n",
        "  with open(fna,'rt') as f:\n",
        "    stz=f.read().splitlines()\n",
        "  stz=('@'.join(stz)).replace('@@','^').split('^')\n",
        "  stz_l=len(stz)\n",
        "  stz_n=[]\n",
        "  for i in range(stz_l):\n",
        "    txt=stz[i]\n",
        "    if txt[0] == '#':\n",
        "      continue\n",
        "    if '@' in txt:\n",
        "      stz2=txt.split('@')\n",
        "      arr=[]\n",
        "      for s in stz2:\n",
        "        arr+=get_real_return(sentUnit(s))\n",
        "      stz_n.append(arr)\n",
        "    else:\n",
        "      stz_n.append( get_real_return(sentUnit(stz[i])) )\n",
        "  return stz_n\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def i2t(strr, ifempty=None):\n",
        "  if strr:\n",
        "    f = float(strr)\n",
        "    if f > 1:\n",
        "      f/=100 \n",
        "    return f\n",
        "  return ifempty\n",
        "\n",
        "def m2mw(strr,prev,p_wgt):\n",
        "  wgt=p_wgt\n",
        "  spl=strr.split('+')\n",
        "  if len(spl)>1:\n",
        "    wgt=float(spl[1])\n",
        "    strr=spl[0]\n",
        "    if strr == '':\n",
        "      strr=prev\n",
        "  return strr,wgt\n",
        "\n",
        "\n",
        "InfoChrs='1234567890+-:. '\n",
        "def findposiblesplit(str_in):\n",
        "  lstr=len(str_in)-1\n",
        "  for n in range(lstr,-1,-1):\n",
        "    if str_in[n] not in InfoChrs:\n",
        "      return n-lstr\n",
        "  return 0\n",
        "\n",
        "def mktaps(str,sep=';',p_wgt=None,p_sta=None,p_end=None):\n",
        "  Enbale_s_in_s = True\n",
        "  if sep != ';':\n",
        "    Enbale_s_in_s=False\n",
        "  segs=str.split(sep)\n",
        "  if len(segs[-1]) == 0:\n",
        "    segs=segs[:-1]\n",
        "  if len(segs[0]) == 0:\n",
        "    segs=segs[1:]\n",
        "  prevstr=''\n",
        "  ret=[]\n",
        "  for s in segs:\n",
        "    sta=p_sta\n",
        "    endo=p_end\n",
        "    repl_msg=None\n",
        "    info_s=s\n",
        "    s_in_s=False\n",
        "    if Enbale_s_in_s and '|' in s:\n",
        "      s_in_s=True\n",
        "      idx=findposiblesplit(s)\n",
        "      if idx == 0:\n",
        "        info_s = 'dummy'\n",
        "        repl_msg=s\n",
        "      else:\n",
        "        info_s = 'dummy'+s[idx:]\n",
        "        repl_msg = s[:idx]\n",
        "\n",
        "    msg=info_s.split(':')\n",
        "    if len(msg) > 2:\n",
        "      sta=i2t(msg[1],p_sta)\n",
        "      endo=i2t(msg[2],p_end)\n",
        "    msg, wgt=m2mw(msg[0],prevstr,p_wgt)\n",
        "    if s_in_s:\n",
        "      msg=repl_msg+msg[5:]\n",
        "\n",
        "    msg=msg.strip()\n",
        "    prevstr=msg\n",
        "    ret.append((msg,wgt,sta,endo))\n",
        "  return ret\n",
        "\n",
        "def m2unit(data,dtal,mtx):\n",
        "  ret=[]\n",
        "  for i in range(dtal):\n",
        "    if mtx[i] !=0xff:\n",
        "      ret.append(data[i])\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def chkrealexist(key,src_n):\n",
        "  if not src_n.repls:\n",
        "    return False\n",
        "  if key in src_n.repls:\n",
        "    return True\n",
        "\n",
        "  return False\n",
        "\n",
        "def vintzproc(src,k,v):\n",
        "  dtal=len(src)\n",
        "  for n in range(dtal):\n",
        "    if chkrealexist(k,src[n]):\n",
        "      vinfo=src[n].repls[k]\n",
        "      brd=vinfo.repl(src[n],v)\n",
        "      if len(brd) == 1:\n",
        "        src[n]=brd[0]\n",
        "      else:\n",
        "        src=src[:n]+brd+src[n+1:]\n",
        "  return src\n",
        "\n",
        "def recurflatten(seed,key_list):\n",
        "  k=key_list[-1]\n",
        "  n_pl=ActivedPromptVars[k].ll\n",
        "  n_seed=len(seed)\n",
        "  newseed=[]\n",
        "  for i in range(n_seed):\n",
        "    for v in range(n_pl):\n",
        "      src=copy.deepcopy(seed[i])\n",
        "      newseed.append( vintzproc(src,k,v) )\n",
        "  if len(key_list) > 1:\n",
        "    return recurflatten(newseed,key_list[:-1])\n",
        "  else:\n",
        "    return newseed\n",
        "\n",
        "def ActivedPromptVarsByCplx():\n",
        "  key_list=list(ActivedPromptVars.keys())\n",
        "  kl=len(key_list)\n",
        "  for n in range(kl):\n",
        "    key=key_list[n]\n",
        "    key_list[n]=('%08X'%ActivedPromptVars[key].cplxLevel(-1))+key\n",
        "  key_list.sort()\n",
        "  for n in range(kl):\n",
        "    key_list[n]=key_list[n][8:]\n",
        "  return key_list\n",
        "\n",
        "\n",
        "def proc3d(data):\n",
        "  key_list=ActivedPromptVarsByCplx()\n",
        "  arr= recurflatten([data],key_list)\n",
        "  arrl=len(arr)\n",
        "  for i in range(arrl):\n",
        "    arr[i]=trimgroup(arr[i])\n",
        "  return arr\n",
        "\n",
        "\n",
        "def proc1d(data):\n",
        "  return [trimgroup(data)]\n",
        "\n",
        "\n",
        "def trymakeemb(tag):\n",
        "  if tag in cond_stage_model.dedup:\n",
        "    return True\n",
        "  if os.path.isfile('UserEmb/'+tag[1:-1]+'.bin'):\n",
        "    cond_stage_model.insert(tag)\n",
        "    return True\n",
        "  return False\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dfind_emb(txt,poz,l,p_wgt,p_sta,p_end):\n",
        "  i=poz\n",
        "  while i < l:\n",
        "    c=txt[i]\n",
        "    i+=1\n",
        "    if c == '>':\n",
        "      sig=txt[poz-1:i]\n",
        "      unit = sentUnit(sig,fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      valid=trymakeemb(sig)\n",
        "      if valid:\n",
        "        unit.set_emb(1)\n",
        "      else:\n",
        "        unit.wgt=-333\n",
        "        unit.msg=sig[1:-1]\n",
        "      return unit, 0 ,i\n",
        "    \n",
        "\n",
        "def dfind_v(txt,poz,l,p_wgt,p_sta,p_end):\n",
        "  i=poz\n",
        "  while i < l:\n",
        "    c=txt[i]\n",
        "    i+=1\n",
        "    if c == '}':\n",
        "      sig=txt[poz-1:i]\n",
        "      unit = sentUnit('}',fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      dmm=vinfo(sig)\n",
        "      if dmm.valid:\n",
        "        unit.repls[sig]=dmm\n",
        "      else:\n",
        "        unit.wgt=-333\n",
        "        unit.msg=sig[1:-1]\n",
        "      return unit, 0 ,i\n",
        "\n",
        "def dfind_v_dummy(txt,poz,l,p_wgt,p_sta,p_end):\n",
        "  i=poz\n",
        "  while i < l:\n",
        "    c=txt[i]\n",
        "    i+=1\n",
        "    if c == '}':\n",
        "      sig=txt[poz:i-1]\n",
        "      unit = sentUnit(sig,fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      unit.wgt=-333\n",
        "      return unit, 0 ,i\n",
        "\n",
        "def dfind_head(txt,poz,l,p_wgt,p_sta,p_end):\n",
        "  i=poz\n",
        "  while i < l:\n",
        "    c=txt[i]\n",
        "    i+=1\n",
        "    if c == '<':\n",
        "      if i - poz > 1:\n",
        "        unit= sentUnit(txt[poz:i-1].strip(),fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      else:\n",
        "        unit= sentUnit('empty',fast=0,p_wgt=-666)\n",
        "      return unit, 1 ,i\n",
        "    elif c == '{':\n",
        "      if i - poz > 1:\n",
        "        unit= sentUnit(txt[poz:i-1].strip(),fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "      else:\n",
        "        unit= sentUnit('empty',fast=0,p_wgt=-666)\n",
        "      return unit, 2 ,i\n",
        "  \n",
        "  fina=sentUnit(txt[poz:].strip(),fast=0,p_wgt=p_wgt,p_sta=p_sta,p_end=p_end)\n",
        "  fina.wgt=-333\n",
        "  return fina,0,l\n",
        "\n",
        "\n",
        "def canmerge(ret):\n",
        "  if len(ret) == 0:\n",
        "    return False\n",
        "  if len(ret[-1].msg) < 2:\n",
        "    return False\n",
        "  if ret[-1].msg[0] == '<':\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def emb_and_v(txt,p_wgt=None,p_sta=None,p_end=None,enable3d=True):\n",
        "  l=len(txt)\n",
        "  i=0\n",
        "  functbl=[dfind_head, dfind_emb, dfind_v]\n",
        "  if not enable3d:\n",
        "    functbl[2]=dfind_v_dummy\n",
        "\n",
        "  finderfunc=dfind_head\n",
        "  ret=[]\n",
        "  while i < l:\n",
        "    result, nfunc, i = finderfunc(txt,i,l,p_wgt,p_sta,p_end)\n",
        "    finderfunc=functbl[nfunc]\n",
        "    if result.wgt == -333:\n",
        "      if canmerge(ret):\n",
        "        ret[-1].msg+=' '+result.msg\n",
        "      else:\n",
        "        result.wgt=p_wgt\n",
        "        ret.append(result)\n",
        "    elif result.wgt != -666:\n",
        "      ret.append(result)\n",
        "\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dumbunit(txt,wgt):\n",
        "  if wgt == 1:\n",
        "    wgt = None\n",
        "  return emb_and_v(txt,p_wgt=wgt)\n",
        "\n",
        "\n",
        "\n",
        "def filltimeinfo(arr,sta,endo,wgtfix):\n",
        "  if not arr:\n",
        "    return 0\n",
        "  for itm in arr:\n",
        "    itm.wgt+=wgtfix \n",
        "    itm.upper=sta\n",
        "    itm.lower=endo\n",
        "  return 1\n",
        "\n",
        "def pp_edb(sta,endo):\n",
        "  prepand=sentUnit('[',fast=1, p_sta=sta,p_end=endo )\n",
        "  lazt_id=prepand.id\n",
        "  edb=sentUnit(']',fast=1)\n",
        "  edb.id=lazt_id\n",
        "  return [prepand],[edb]\n",
        "\n",
        "def flattenretk(retk):\n",
        "  ret=retk[0]\n",
        "  retkl=len(retk)\n",
        "  if retkl == 2:\n",
        "    ret[0].wgt=float(retk[1][0].msg)\n",
        "  elif retkl > 2:\n",
        "    timeinfo=float(retk[2][0].msg)\n",
        "    hazcot=0\n",
        "    hazcot+=filltimeinfo(ret,None,timeinfo,0.1)\n",
        "    hazcot+=filltimeinfo(retk[1],timeinfo,None,0.1)\n",
        "    if hazcot > 1:\n",
        "      pp, edb = pp_edb(None,timeinfo)\n",
        "      ret=pp+ret+edb\n",
        "      pp, edb = pp_edb(timeinfo,None)\n",
        "      erz_id=pp[0].id\n",
        "      ret[0].eraz[erz_id]=erz_id\n",
        "      retk[1]=pp+retk[1]+edb\n",
        "\n",
        "    ret+=retk[1]\n",
        "\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "def parsedumbformat(txt,sta=0,l=-1,wgt=1,sqq=False):\n",
        "  cut0=sta\n",
        "  if l < 0:\n",
        "    l=len(txt)\n",
        "  retk=[[]]\n",
        "  ptidx=0\n",
        "\n",
        "\n",
        "  i=sta\n",
        "  while i < l:\n",
        "    c=txt[i]\n",
        "    i+=1\n",
        "    if c == '(':\n",
        "      if i-cut0>1:\n",
        "        retk[ptidx]+=dumbunit(txt[cut0:i-1],wgt)\n",
        "      cut0, ret = parsedumbformat(txt,i,l,wgt+0.1,sqq=True)\n",
        "      i=cut0\n",
        "      retk[ptidx]+=ret\n",
        "    elif c == '[':\n",
        "      if i-cut0>1:\n",
        "        retk[ptidx]+= dumbunit(txt[cut0:i-1],wgt) \n",
        "      cut0, ret = parsedumbformat(txt,i,l,wgt-0.1,sqq=True)\n",
        "      i=cut0\n",
        "      retk[ptidx]+=ret\n",
        "    elif c == ')':\n",
        "      if i-cut0>1:\n",
        "        retk[ptidx]+= dumbunit(txt[cut0:i-1],wgt) \n",
        "      return i,flattenretk(retk)\n",
        "    elif c == ']':\n",
        "      if i-cut0>1:\n",
        "        retk[ptidx]+= dumbunit(txt[cut0:i-1],wgt)\n",
        "        return i,flattenretk(retk)\n",
        "    elif sqq and c == ':':\n",
        "      if i-cut0>1:\n",
        "        retk[ptidx]+= dumbunit(txt[cut0:i-1],wgt) \n",
        "      cut0=i\n",
        "      ptidx+=1\n",
        "      retk.append([])\n",
        "\n",
        "\n",
        "  retk=flattenretk(retk)\n",
        "  if cut0<l:\n",
        "    retk+= dumbunit(txt[cut0:],wgt) \n",
        "  return retk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pmpmtx(data_in,nsamp=1,cuda=True,fromtxt=True,enable3d=True):\n",
        "  if len(data_in[0]) == 0:\n",
        "    return [cond_getter(None,nsamp=nsamp,cuda=cuda)]\n",
        "  arr = pmpmtx_preproc(data_in,fromtxt=fromtxt,enable3d=enable3d)\n",
        "\n",
        "  arrl=len(arr)\n",
        "  for c in range(arrl):\n",
        "    arr_for_getter, fastmode,txt, kndref = to_arr_for_getter(arr[c],nsamp=nsamp,cuda=cuda)\n",
        "    arr[c]=cond_getter(arr_for_getter,fast=fastmode,reftxt=txt,kndref=kndref)\n",
        "  return arr\n",
        "\n",
        "\n",
        "def pmpmtx_preproc(data_in,fromtxt=True,enable3d=True):\n",
        "  global ActivedPromptVars\n",
        "  ActivedPromptVars=dict()\n",
        "  arr=[]\n",
        "\n",
        "  if fromtxt:\n",
        "    if len(data_in) == 1:\n",
        "      if '((' in data_in[0]:\n",
        "        arr=parsedumbformat(data_in[0])\n",
        "      else:\n",
        "        arr= emb_and_v(data_in[0], enable3d=enable3d)\n",
        "    else:\n",
        "      for d in data_in:\n",
        "        if d[0] != '#':\n",
        "          arr+=get_real_return(sentUnit(d))\n",
        "  else:\n",
        "    arr=data_in\n",
        "\n",
        "  if enable3d and ActivedPromptVars:\n",
        "    arr=proc3d(arr)\n",
        "  else:\n",
        "    ActivedPromptVars=dict()\n",
        "    arr=proc1d(arr)\n",
        "  return arr\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def to_arr_for_getter(data,nsamp=1,cuda=True):\n",
        "  dtal=len(data)\n",
        "  cpy_ones=np.ones(t_enc,dtype=np.uint8)\n",
        "  cpy_eraz=cpy_ones*0xff\n",
        "  mtx=np.ones((dtal,t_enc),dtype=np.uint8)\n",
        "\n",
        "  txtid=-1\n",
        "  txtkole=[]\n",
        "  notTime=True\n",
        "  for i in range(dtal):\n",
        "    dta_i=data[i]\n",
        "    sig = dta_i.get_sig()\n",
        "    if sig > 0xFF:\n",
        "      notTime=False\n",
        "      mtx[i]*=0xFF\n",
        "\n",
        "      \n",
        "      sta0, end0 = dta_i.get_realstaend()\n",
        "      \n",
        "      mtx[i][sta0:end0]=cpy_ones[sta0:end0]\n",
        "\n",
        "      if sig > 0xfff:\n",
        "        erazd=dta_i.eraz\n",
        "        for k in erazd:\n",
        "          sta1, end1=erazd[k].get_realstaend()\n",
        "          mtx[i][sta1:end1]=cpy_eraz[sta1:end1]\n",
        "\n",
        "  if notTime:\n",
        "    emb, wgt, txt = cond_stage_model.mk_emb_wgt(data,dtal)\n",
        "    arr = cond_stage_model.from_emb(emb,wgt_arr=wgt,nsamp=nsamp,cuda=cuda)\n",
        "    return  arr, 1, txt, None #arr, fastmode, txt\n",
        "\n",
        "\n",
        "  mtx=mtx.transpose((1,0))\n",
        "  knd=np.ones(t_enc,dtype=np.uint8)\n",
        "  ar2i=dict()\n",
        "  i2txt=[]\n",
        "  txtid=0\n",
        "  for i in range(t_enc):\n",
        "    sig=str(mtx[i].tobytes())[2:-1].replace('\\\\','')\n",
        "    if sig in ar2i:\n",
        "      i_sig=ar2i[sig]\n",
        "    else:\n",
        "      ar2i[sig]=txtid\n",
        "      i2txt.append( m2unit(data,dtal,mtx[i]) )\n",
        "      i_sig=txtid\n",
        "      txtid+=1\n",
        "    knd[i]=i_sig\n",
        "  \n",
        "\n",
        "  if knd.sum() == 0:\n",
        "    emb, wgt, txt = cond_stage_model.mk_emb_wgt(i2txt[0])\n",
        "    arr = cond_stage_model.from_emb(emb,wgt_arr=wgt,nsamp=nsamp,cuda=cuda)\n",
        "    return  arr, 1, txt, None\n",
        "  \n",
        "  knd_arr=[None]*t_enc\n",
        "  knd_arr_txt=[None]*t_enc\n",
        "  enc_l=len(i2txt)\n",
        "\n",
        "  txtk=[None]*enc_l\n",
        "  for i in range(enc_l):\n",
        "    emb, wgt, txt = cond_stage_model.mk_emb_wgt(i2txt[i])\n",
        "    i2txt[i] = cond_stage_model.from_emb(emb,wgt_arr=wgt,nsamp=nsamp,cuda=cuda)\n",
        "    txtk[i]=txt\n",
        "  \n",
        "  for i in range(t_enc):\n",
        "    poo=knd[i]\n",
        "    knd_arr[i]=i2txt[poo]\n",
        "    knd_arr_txt[i]=txtk[poo]\n",
        "\n",
        "  return  knd_arr, -1, knd_arr_txt, knd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def wgtfix0(wgt):\n",
        "  if wgt is None:\n",
        "    return None\n",
        "  elif wgt > 2:\n",
        "    return 1+0.1*wgt\n",
        "  elif wgt < -2:\n",
        "    return -1+0.1*wgt\n",
        "  else:\n",
        "    return wgt\n",
        "  \n",
        "  \n",
        "def wgtfix(b):\n",
        "  b.wgt=wgtfix0(b.wgt)\n",
        "  return b\n",
        "\n",
        "\n",
        "def trimdpth(dyp):\n",
        "  ret=[]\n",
        "  for i in range(9,-1,-1):\n",
        "    if dyp[i]:\n",
        "      ret+=list(dyp[i])\n",
        "  return ret\n",
        "\n",
        "def trimgroup(unit_arr):\n",
        "  bdict=dict()\n",
        "  stapoz=dict()\n",
        "  \n",
        "\n",
        "  ul=len(unit_arr)\n",
        "  dyp=[]\n",
        "  for i in range(10):\n",
        "    dyp.append(set())\n",
        "  depth=0\n",
        "  clean_ret=[]\n",
        "  for i in range(ul):\n",
        "    b=unit_arr[i]\n",
        "    bmsg=b.msg\n",
        "    if len(bmsg) == 1:\n",
        "      if bmsg == '[':\n",
        "        depth+=1\n",
        "        dyp[depth].add(b.id)\n",
        "        bdict[b.id]=b\n",
        "        stapoz[b.id]=[i+1,None]\n",
        "      elif bmsg == ']':\n",
        "        depth-=1\n",
        "        stapoz[b.id][1]=i\n",
        "    else:\n",
        "      clean_ret.append(wgtfix(b))\n",
        "\n",
        "  dyp=trimdpth(dyp)\n",
        "  if len(dyp) == 0:\n",
        "    return clean_ret\n",
        "  \n",
        "  for k in dyp:\n",
        "    sta, endo =stapoz[k]\n",
        "    bdict[k].wgt=endo-sta+1\n",
        "\n",
        "\n",
        "\n",
        "  for k in dyp:\n",
        "    sta, endo =stapoz[k]\n",
        "    b=bdict[k]\n",
        "    nfo=b.eraz\n",
        "    isany=False\n",
        "\n",
        "    for erzid in nfo:\n",
        "      cur=bdict[erzid]\n",
        "      b.eraz[erzid]=cur\n",
        "      isany=True\n",
        "      if cur.yetproc:\n",
        "        sta2, endo2 =stapoz[erzid]\n",
        "        _,_,cur_osta, cur_oendo = cur.nfo(trans_sta=True,trans_end=True)\n",
        "        for i in range(sta2,endo2):\n",
        "          msg,_, cmp_osta, cmp_oendo = unit_arr[i].nfo(trans_sta=True,trans_end=True)\n",
        "          if msg != ']':\n",
        "            if cmp_osta < cur_osta:\n",
        "              cur_osta=cmp_osta\n",
        "            if cmp_oendo > cur_oendo:\n",
        "              cur_oendo = cmp_oendo\n",
        "        cur.upper=cur_osta\n",
        "        cur.lower=cur_oendo\n",
        "        cur.yetproc=False\n",
        "        \n",
        "\n",
        "    if isany:\n",
        "      mergedict(unit_arr,b.eraz,sta,endo)\n",
        "      b.eraz=None\n",
        "\n",
        "\n",
        "   \n",
        "  return clean_ret\n",
        "\n",
        "\n",
        "def mergedict(unit_arr,b_eraz,sta,endo):\n",
        "  for n in range(sta,endo):\n",
        "    ue=unit_arr[n]\n",
        "    if ue.id == 0:\n",
        "      if ue.eraz:\n",
        "        for k in b_eraz:\n",
        "          ue.eraz[k]=b_eraz[k]\n",
        "      else:\n",
        "        ue.eraz=b_eraz\n",
        "\n",
        "def tenzclamp(tenz,tolen=77):\n",
        "  dup=int(0.9999+(tolen/tenz.size(0)))\n",
        "  return torch.cat([tenz]*dup)[:tolen]\n",
        "\n",
        "\n",
        "def prmt_bin(binfna,nsamp=1,cuda=True):\n",
        "  if '%' in binfna:\n",
        "    bink=[]\n",
        "    for i in range(78):\n",
        "      nfna=binfna%i\n",
        "      if os.path.isfile(nfna):\n",
        "        bink.append( torch.tensor( np.fromfile(nfna,dtype=np.float32) ).reshape((-1,768)) )\n",
        "    tenz = tenzclamp(torch.cat(bink))\n",
        "  else:\n",
        "    tenz = tenzclamp( torch.tensor( np.fromfile(binfna,dtype=np.float32) ).reshape((-1,768)) )\n",
        "\n",
        "  tenz=tenz.expand(nsamp,-1,-1)\n",
        "  if cuda:\n",
        "    tenz=tenz.cuda()\n",
        "\n",
        "  return [cond_getter(tenz,fast=1)]\n",
        "  \n",
        "\n",
        "def calcknd(knd_arr,ptxt):\n",
        "  knd_arr = np.stack(knd_arr).transpose((1,0))\n",
        "  ar2i=dict()\n",
        "  i2txt=[]\n",
        "  txtid=0\n",
        "  hgt,prmpl=knd_arr.shape\n",
        "\n",
        "  kndmap=np.ones(hgt,dtype=np.uint8)\n",
        "\n",
        "  for i in range(hgt):\n",
        "    sig=str(knd_arr[i].tobytes())[2:-1].replace('\\\\','')\n",
        "    if sig in ar2i:\n",
        "      i_sig=ar2i[sig]\n",
        "    else:\n",
        "      ar2i[sig]=txtid\n",
        "      i2txt.append( i )\n",
        "      i_sig=txtid\n",
        "      txtid+=1\n",
        "    kndmap[i]=i_sig\n",
        "\n",
        "\n",
        "  stk=len(i2txt)\n",
        "  for i in range(0,prmpl):\n",
        "    stacking=[None]*stk\n",
        "    ge=ptxt[i]\n",
        "\n",
        "    for n in range(stk):\n",
        "      stacking[n]=ge.get(i2txt[n])\n",
        "    ptxt[i]=torch.stack(stacking)\n",
        "\n",
        "  return kndmap\n",
        "\n",
        "def kmapout(kndmap,calc_result):\n",
        "  stk=kndmap.shape[0]\n",
        "  cout2=[None]*stk\n",
        "\n",
        "  for i in range(stk):\n",
        "    cout2[i]=calc_result[ kndmap[i] ]\n",
        "  return cout2\n",
        "\n",
        "def prmt_avg(ptxt,pwgt,prmpl):\n",
        "  knd_arr=[None]*prmpl\n",
        "  cplx=False\n",
        "  for i in range(prmpl):\n",
        "    if not ptxt[i].is_simp:\n",
        "      cplx=True\n",
        "    knd_arr[i] = ptxt[i].get_knd()\n",
        "  \n",
        "  if cplx:\n",
        "    kndmap =calcknd( knd_arr, ptxt )\n",
        "    \n",
        "\n",
        "    cout=ptxt[0]*pwgt[0]\n",
        "    for i in range(1,prmpl):\n",
        "      cout+=(ptxt[i]*pwgt[i])\n",
        "\n",
        "    \n",
        "    cout2=kmapout(kndmap,cout)\n",
        "    \n",
        "\n",
        "    return [ cond_getter( cout2,kndref=kndmap ) ]\n",
        "\n",
        "  cout=ptxt[0].get(0)*pwgt[0]\n",
        "  for i in range(1,prmpl):\n",
        "    cout+=(ptxt[i].get(0)*pwgt[i])\n",
        "  return [ cond_getter( cout,fast=1 )]\n",
        "\n",
        "\n",
        "def prmt_dymc(stz,cuda):\n",
        "  prmpl=len(stz)>>1\n",
        "  ptxt=[]\n",
        "  pstp=[0]\n",
        "  stpsum=1\n",
        "  for i in range(prmpl):\n",
        "    ptxt.append(  makeCs(stz[2*i],1, cuda=cuda,enable3d=False )[0]  )\n",
        "    soi=float(stz[2*i+1])\n",
        "    stpsum+=soi\n",
        "    pstp.append(  stpsum  )\n",
        "\n",
        "  for i in range(prmpl):\n",
        "    pstp[i+1]=int(0.5+(pstp[i+1]/stpsum)*t_enc)\n",
        "\n",
        "  bs_knd=ptxt[0].get_knd().astype(np.uint16)\n",
        "  bs_arr=ptxt[0].get_fullarr()\n",
        "  for i in range(1,prmpl):\n",
        "    cut0=pstp[i]\n",
        "    bs_knd[cut0:]=ptxt[i].get_knd()[cut0:].astype(np.uint16)+0x100*i\n",
        "    bs_arr[cut0:]=ptxt[i].get_fullarr()[cut0:]\n",
        "\n",
        "  return [ cond_getter( bs_arr, kndref=bs_knd ) ]\n",
        "\n",
        "\n",
        "def prmt_intp_cplx(ptxt,pstp,knd_arr,prmpl):\n",
        "  kndmap =calcknd( knd_arr, ptxt )\n",
        "\n",
        "  intpos=[]\n",
        "  for vv in range(prmpl):\n",
        "    c1=ptxt[vv]\n",
        "    c2=ptxt[vv+1]\n",
        "    stp=pstp[vv]\n",
        "    for i in range(stp):\n",
        "      cn= kmapout(kndmap, (c2*i+c1*(stp-i))/stp )\n",
        "      intpos.append( cond_getter(cn, kndref=kndmap) )\n",
        "\n",
        "  lztbk=pstp[-1]\n",
        "  if lztbk > 1:\n",
        "    c1=ptxt[prmpl]\n",
        "    c2=ptxt[0]\n",
        "    for i in range(lztbk):\n",
        "      cn=kmapout(kndmap, (c2*i+c1*(lztbk-i))/lztbk )\n",
        "      intpos.append( cond_getter(cn, kndref=kndmap) )\n",
        "  else:\n",
        "    cn = kmapout(kndmap,ptxt[-1])\n",
        "    intpos.append( cond_getter(cn, kndref=kndmap) )\n",
        "  return intpos\n",
        "\n",
        "def prmt_intp(stz,cuda):\n",
        "  prmpl=len(stz)>>1\n",
        "  ptxt=[None]*prmpl\n",
        "  pstp=[None]*prmpl\n",
        "  knd_arr=[None]*prmpl\n",
        "  cplx=False\n",
        "  for i in range(prmpl):\n",
        "    ge=makeCs(stz[2*i],1, cuda=cuda,enable3d=False )[0]\n",
        "    knd_arr[i] = ge.get_knd()\n",
        "    if not ge.is_simp:\n",
        "      cplx=True\n",
        "    ptxt[i]=  ge  \n",
        "    pstp[i]=  int(stz[2*i+1])+1  \n",
        "  prmpl-=1\n",
        "\n",
        "  if cplx:\n",
        "    return prmt_intp_cplx(ptxt,pstp,knd_arr,prmpl)\n",
        "  \n",
        "  intpos=[]\n",
        "  for vv in range(prmpl):\n",
        "    c1=ptxt[vv].get(0)\n",
        "    c2=ptxt[vv+1].get(0)\n",
        "    stp=pstp[vv]\n",
        "    for i in range(stp):\n",
        "      cn=(c2*i+c1*(stp-i))/stp\n",
        "      intpos.append( cond_getter(cn,fast=1) )\n",
        "\n",
        "  lztbk=pstp[-1]\n",
        "  if lztbk > 1:\n",
        "    c1=ptxt[prmpl].get(0)\n",
        "    c2=ptxt[0].get(0)\n",
        "    for i in range(lztbk):\n",
        "      cn=(c2*i+c1*(lztbk-i))/lztbk\n",
        "      intpos.append( cond_getter(cn,fast=1) )\n",
        "  else:\n",
        "    intpos.append(ptxt[-1])\n",
        "  return intpos\n",
        "\n",
        "def printprompts(detailed=False):\n",
        "  k=0\n",
        "  for c in c_list:\n",
        "    tstr='PromptV'+str(k)+' at step'\n",
        "    k+=1\n",
        "    if c.txt:\n",
        "      print(tstr+'0:')\n",
        "      print(c.get_txt(0))\n",
        "      if detailed and c.knd is not None:\n",
        "        knd=c.knd\n",
        "        prev=knd[0]\n",
        "        knd_l=len(knd)\n",
        "        for j in range(knd_l):\n",
        "          cur=knd[j]\n",
        "          if cur != prev:\n",
        "            prev=cur\n",
        "            print(tstr+str(j)+':')\n",
        "            print(c.get_txt(j))\n",
        "\n",
        "depthLimit=10\n",
        "\n",
        "def txtErr(prmt0,msg):\n",
        "  print(msg)\n",
        "  prmt=prmt0.split('/')[-1][:-4]\n",
        "  print('err prompt: '+prmt)\n",
        "  return pmpmtx([prmt0],nsamp=n_samples,enable3d=False)\n",
        "\n",
        "\n",
        "def cmdtype(cmd0):\n",
        "  if cmd0.startswith('intp:'):\n",
        "    return 1\n",
        "  elif cmd0.startswith('dymc:'):\n",
        "    return 2\n",
        "  elif cmd0.startswith('mad:'):\n",
        "    return 10\n",
        "  elif cmd0.startswith('avg:'):\n",
        "    return 11\n",
        "  return 0\n",
        "\n",
        "rtdir=''\n",
        "def makeCs(prmt,depth=0,cuda=True,enable3d=True):\n",
        "  global rtdir\n",
        "  if prmt.endswith('.txt'):\n",
        "    if depth > depthLimit:\n",
        "      return txtErr(prmt,'Too many ref, probably circular reference.')\n",
        "    if depth==0:\n",
        "      rtdir=''\n",
        "      try:\n",
        "        rtdir=prmt[:prmt.rindex('/')+1]\n",
        "      except:\n",
        "        pass\n",
        "    depth+=1\n",
        "    if not os.path.isfile(prmt):\n",
        "      prmt=rtdir+prmt\n",
        "      if not os.path.isfile(prmt):\n",
        "        return txtErr(prmt,'ref not found.')\n",
        "    with open(prmt,'rt') as f:\n",
        "      stz=f.read().splitlines()\n",
        "    cmd=stz[0].replace(' ','').replace('\\t','').split('/')\n",
        "    cmd0=cmdtype(cmd[0])\n",
        "    if cmd0 == 0:\n",
        "      return pmpmtx(stz,nsamp=n_samples,cuda=cuda,enable3d=enable3d)\n",
        "    elif cmd0 == 1:\n",
        "      if depth > 1:\n",
        "        return txtErr(stz[1],'do not intp in ref')\n",
        "      return prmt_intp(stz[1:],cuda=cuda)\n",
        "    elif cmd0 == 2:\n",
        "      return prmt_dymc(stz[1:],cuda=cuda)\n",
        "\n",
        "\n",
        "    prmpl=(len(stz)-1)>>1\n",
        "    stz=stz[1:]\n",
        "    ptxt=[]\n",
        "    pwgt=[]\n",
        "    wgtsum=0\n",
        "    for i in range(prmpl):\n",
        "      ptxt.append(  makeCs(stz[2*i],depth, cuda=cuda,enable3d=False )[0]  )\n",
        "      wgt=float(stz[2*i+1])\n",
        "      wgtsum+=wgt\n",
        "      pwgt.append(  wgt  )\n",
        "    if cmd0 == 11:\n",
        "      for i in range(prmpl):\n",
        "        pwgt[i]=pwgt[i]/wgtsum\n",
        "    \n",
        "    return prmt_avg(ptxt,pwgt,prmpl)\n",
        "\n",
        "  elif prmt.endswith('.bin'):\n",
        "    return prmt_bin(prmt,nsamp=n_samples,cuda=cuda)\n",
        "  else:\n",
        "    return pmpmtx([prmt],nsamp=n_samples,cuda=cuda,enable3d=enable3d)"
      ],
      "metadata": {
        "id": "Jh2EIFS99q3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.isfile('PromptFuncsExample/MultiPrompt_average.txt'):\n",
        "  t3 = Thread(target = dlpromptexample)\n",
        "  a3 = t3.start()"
      ],
      "metadata": {
        "id": "yh5Ms_sLOk_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Super Resolution 4x<br>\n",
        "Select one of these task: Super Resolution, txt2img, (old ldm)infilling"
      ],
      "metadata": {
        "id": "115Y_TyxYkbk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4vrU_GL_6f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrSkT1_5AJSr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2UYWGCLIKSFS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: SD lat decoder"
      ],
      "metadata": {
        "id": "_jVyaZSmEfPx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "TUrKQWmQFo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: GFPgan-jit"
      ],
      "metadata": {
        "id": "c79C9jECmn-C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "yKhdSfpTmsiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOqZ0K2Rm_G4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# txt2img"
      ],
      "metadata": {
        "id": "PWCzxzNkYpEr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmYgI8PLYudK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👇Optional👇"
      ],
      "metadata": {
        "id": "E4dG4ZxdW4y-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQlZQgl7uxkx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_stage_model.insert('<majipuri>')\n",
        "cond_stage_model.insert('<pekora>')"
      ],
      "metadata": {
        "id": "x0KSuj8yEZmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_stage_model.insert_prompt_vars('animals')\n",
        "cond_stage_model.insert_prompt_vars('artists')"
      ],
      "metadata": {
        "id": "y9hFuhPnE4DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1FtIJmB2Ojd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "infilling"
      ],
      "metadata": {
        "id": "G2ANdLCfXTj9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rkrl24HWW31Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt interpolation with latent re-feeding"
      ],
      "metadata": {
        "id": "B6VrT6bw0tUd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "Pgy-4fQn0sT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NoiseMap interpolation<br>re-feed previous when strength > 0"
      ],
      "metadata": {
        "id": "Ht69eCNYt5VW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "JNB7IAIMt_YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "☝️Optional☝️"
      ],
      "metadata": {
        "id": "QunwpFSGXKz3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5xaKk_uYwBK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "pH0ExQ__p8Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 3 -i /content/sample_data/48_0x3v%d.png intp03.mp4"
      ],
      "metadata": {
        "id": "Yby8cQ9HqkuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools\n",
        "designed for the gen proc running with `InThread` or gradio app<br>\n",
        "so imgenc (image->latent encoder) is on cpu"
      ],
      "metadata": {
        "id": "vFqWsqyVNB2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-pix_fmt yuv420p\n",
        "hlog0.setfuncb('log')"
      ],
      "metadata": {
        "id": "uiJvF6-N2pUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/sample_data/vyi\n",
        "for n in range(200):\n",
        "  Image.fromarray( (( ( latdec2(hlog0.latlog[n])[0] +1)*127.5 ).cpu().numpy()).transpose(1,2,0).clip(0,255).astype(np.uint8) ).save('/content/sample_data/vyi/stp%05d.png'%n)"
      ],
      "metadata": {
        "id": "QeNF5VjH2hqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.link('/content/sample_data/64_7x0v1.png','/content/sample_data/vyi/stp00100.png')"
      ],
      "metadata": {
        "id": "YVZn3yJA20g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hlog0.latlog=[]"
      ],
      "metadata": {
        "id": "ICOv0Vv42rnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConcatNoise=ConcatNoise_rdm #ConcatNoise_shuf"
      ],
      "metadata": {
        "id": "t9SaQkepZTLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gif/Video to latent pack"
      ],
      "metadata": {
        "id": "_9d7uJg9NEPA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "MmRwF523NIZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize the output to `(64*n)x(64*m)` first"
      ],
      "metadata": {
        "id": "GLrbLP9cN8oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encodepatt()"
      ],
      "metadata": {
        "id": "ckwYthEQOJSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "cellView": "form",
        "id": "GxQjN-yyggf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgemb(load_im('/content/chaz512.jpg')).numpy().tofile('chaz.bin')"
      ],
      "metadata": {
        "id": "qk9SKnUkgifF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Gui\n",
        "tho I don't really understand why you want a webui inside another webui"
      ],
      "metadata": {
        "id": "bJsLMq9pplwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradio=False #@param {type:'boolean'}\n",
        "\n",
        "!pip install gradio\n",
        "from google.colab import output\n",
        "import gradio as gr\n",
        "\n",
        "def dream():\n",
        "  return\n",
        "\n",
        "\n",
        "dream_interface = gr.Interface(\n",
        "    dream,\n",
        "    inputs=[\n",
        "        gr.Textbox(placeholder=\"A corgi wearing a top hat as an oil painting.\", lines=1),\n",
        "        gr.Slider(minimum=1, maximum=150, step=1, label=\"Sampling Steps\", value=50),\n",
        "        gr.Checkbox(label='Enable PLMS sampling', value=False),\n",
        "        gr.Checkbox(label='Enable Fixed Code sampling', value=False),\n",
        "        gr.Slider(minimum=0.0, maximum=1.0, step=0.01, label=\"DDIM ETA\", value=0.0, visible=False),\n",
        "        gr.Slider(minimum=1, maximum=50, step=1, label='Sampling iterations', value=8),\n",
        "        gr.Slider(minimum=1, maximum=8, step=1, label='Samples per iteration', value=1),\n",
        "        gr.Slider(minimum=1.0, maximum=20.0, step=0.5, label='Classifier Free Guidance Scale', value=7.0),\n",
        "        gr.Number(label='Seed', value=-1),\n",
        "        gr.Slider(minimum=64, maximum=2048, step=64, label=\"Height\", value=704),\n",
        "        gr.Slider(minimum=64, maximum=2048, step=64, label=\"Width\", value=768),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Gallery(),\n",
        "        gr.Number(label='Seed')\n",
        "    ],\n",
        "    title=\"Stable Diffusion Text-to-Image\",\n",
        "    description=\"Generate images from text with Stable Diffusion\",\n",
        ")\n",
        "\n",
        "\n",
        "gdemo = gr.TabbedInterface(interface_list=[dream_interface], tab_names=[\"Dream\"])\n",
        "\n",
        "\n",
        "output.serve_kernel_port_as_window(8233, path='/dl.htm')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mh-_HQ1jquy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the link above to `GoogleLocal`"
      ],
      "metadata": {
        "id": "ePW4zpPPsVTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GoogleLocal = 'aaaaa' #@param {type:'string'}\n",
        "if '.googleusercontent.com' in GoogleLocal:\n",
        "  gdemo.launch()\n",
        "else:\n",
        "  print('set a valid GoogleLocal')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ndCPoghArlfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# glid-3-xl-stable"
      ],
      "metadata": {
        "id": "O6t9w7xdHv6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SDver='470k' #@param ['440k', '470k']\n",
        "Dfm='Orig' #@param ['Orig', '_imgemb','_a19561','_a17750','_a17750_e9750','_e26500']\n",
        "if Dfm=='Orig':\n",
        "  Dfm=''\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "torch.set_num_threads(os.cpu_count())\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class imgencdec:\n",
        "  def encode(self,im):\n",
        "    nzmp=im.size(0)\n",
        "    H=im.size(2)\n",
        "    W=im.size(3)\n",
        "    return imgenc(  im, torch.randn(torch.Size([nzmp,4,H>>3,W>>3]))  )\n",
        "  def decode(self,im):\n",
        "    return autoencoder(im)\n",
        "\n",
        "\n",
        "SDver=f_dljit(SDver,Dfm)\n",
        "\n",
        "if not os.path.isfile('/content/guided_diffusion/unet.py'):\n",
        "  !wget https://raw.githubusercontent.com/TabuaTambalam/DalleWebms/main/docs/sd/jkt.py\n",
        "  !git clone https://github.com/Jack000/glid-3-xl-stable.git\n",
        "  !mv /content/glid-3-xl-stable/guided_diffusion /content/guided_diffusion \n",
        "\n",
        "from transformers import CLIPTokenizer\n",
        "cond_stage_model = BERTEmbedder(torch.jit.load('transformer_pnnx.pt').eval())\n",
        "diffusion_emb = torch.jit.load(SDver+'diffusion_emb_pnnx.pt').eval().cuda()\n",
        "diffusion_mid = torch.jit.load(SDver+'diffusion_mid_pnnx.pt').eval().cuda()\n",
        "diffusion_out = torch.jit.load(SDver+'diffusion_out_pnnx.pt').eval().cuda()\n",
        "autoencoder = torch.jit.load('autoencoder_pnnx.pt').eval().cuda()\n",
        "SDlatDEC=autoencoder\n",
        "imgenc = torch.jit.load('imgencoder_pnnx.pt').eval()"
      ],
      "metadata": {
        "id": "2cz08wFzH-8L",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://huggingface.co/Jack000/glid-3-xl-stable/tree/main/super_lg\n",
        "import gc\n",
        "import io\n",
        "import math\n",
        "import sys\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from guided_diffusion.script_util import create_model_and_diffusion, model_and_diffusion_defaults\n",
        "\n",
        "\n",
        "from accelerate import init_empty_weights\n",
        "from einops import rearrange\n",
        "from math import log2, sqrt\n",
        "\n",
        "\n",
        "!mkdir output_npy\n",
        "!mkdir output\n",
        "\n",
        "def save_sample(i, sample, clip_score=False):\n",
        "    for k, image in enumerate(sample['pred_xstart'][:1]):\n",
        "        image /= 0.18215\n",
        "        im = image.unsqueeze(0)\n",
        "        out = ldm.decode(im)\n",
        "\n",
        "        npy_filename = f'output_npy/{i * batchsz + k:05}.npy'\n",
        "        with open(npy_filename, 'wb') as outfile:\n",
        "            np.save(outfile, image.detach().cpu().numpy())\n",
        "\n",
        "        out = TF.to_pil_image(out.squeeze(0).add(1).div(2).clamp(0, 1))\n",
        "\n",
        "        filename = f'output/{i * batchsz + k:05}.png'\n",
        "        out.save(filename)\n",
        "\n",
        "\n",
        "# Create a classifier-free guidance sampling function\n",
        "def model_fn(x_t, ts, **kwargs):\n",
        "    half = x_t[: len(x_t) // 2]\n",
        "    combined = torch.cat([half, half], dim=0)\n",
        "    model_out = model(combined, ts, **kwargs)\n",
        "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "    cond_eps, uncond_eps = torch.split(eps, len(eps) // 2, dim=0)\n",
        "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "    eps = torch.cat([half_eps, half_eps], dim=0)\n",
        "    return torch.cat([eps, rest], dim=1)\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device)\n",
        "\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    'attention_resolutions': '32,16,8',\n",
        "    'class_cond': False,\n",
        "    'diffusion_steps': 1000,\n",
        "    'rescale_timesteps': True,\n",
        "    'timestep_respacing': '50',  # Modify this value to decrease the number of\n",
        "                                 # timesteps.\n",
        "    'image_size': 32,\n",
        "    'learn_sigma': False,\n",
        "    'noise_schedule': 'linear',\n",
        "    'num_channels': 320,\n",
        "    'num_heads': 8,\n",
        "    'num_res_blocks': 2,\n",
        "    'resblock_updown': False,\n",
        "    'use_fp16': False,\n",
        "    'use_scale_shift_norm': False,\n",
        "    'clip_embed_dim': None, #768,\n",
        "    'image_condition': False,\n",
        "    #'image_condition': True if model_state_dict['input_blocks.0.0.weight'].shape[1] == 8 else False,\n",
        "    'super_res_condition': False,\n",
        "}\n",
        "\n",
        "model_params['timestep_respacing'] = '100'\n",
        "\n",
        "model_config = model_and_diffusion_defaults()\n",
        "model_config.update(model_params)\n",
        "\n",
        "\n",
        "model_config['use_fp16'] = True\n",
        "\n",
        "# Load models\n",
        "with init_empty_weights():\n",
        "  model, diffusion = create_model_and_diffusion(**model_config)\n",
        "\n",
        "load_state_dict_with_low_memory(model,mkmodel_state_dict())\n",
        "\n",
        "if model_config['use_fp16']:\n",
        "  model.convert_to_fp16()"
      ],
      "metadata": {
        "id": "Qpp_f7ZWIIWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.requires_grad_(False).eval().to(device)\n",
        "\n",
        "\n",
        "torch.manual_seed(114514)\n",
        "\n",
        "\n",
        "# vae\n",
        "\n",
        "ldm=imgencdec()\n",
        "\n",
        "\n",
        "guidance_scale=7\n",
        "height=832\n",
        "width=896\n",
        "batchsz=1\n",
        "\n",
        "\n",
        "args_text='thicc farm girl, long blonde hair, japanimation, by Alfons Maria Mucha, cinematic lightning, cinematic wallpaper'\n",
        "args_negative=''\n",
        "# clip context\n",
        "\n",
        "n_samples=batchsz\n",
        "t_enc=100\n",
        "text_emb = makeCs(args_text)[0].get(0)\n",
        "text_emb_blank = makeCs(args_negative)[0].get(0)\n",
        "\n",
        "image_embed = None\n",
        "\n",
        "\n",
        "\n",
        "input_image = torch.zeros(batchsz, 4, height//8, width//8, device=device)\n",
        "'''\n",
        "lat=torch.tensor(np.load('96_4x1v1.npy'))\n",
        "\n",
        "\n",
        "input_image[0][:,:,:32]=lat[0][:,:,:32]\n",
        "'''\n",
        "\n",
        "      \n",
        "image_embed = None #torch.cat(batchsz*2*[input_image], dim=0).float()\n",
        "\n",
        "\n",
        "\n",
        "kwargs = {\n",
        "    \"context\": torch.cat([text_emb, text_emb_blank], dim=0).half().cuda(),\n",
        "    \"clip_embed\": None,\n",
        "    \"image_embed\": image_embed\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "cur_t = None\n",
        "\n",
        "sample_fn = diffusion.plms_sample_loop_progressive\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "init = Image.open('xipooh.jpg').convert('RGB')\n",
        "\n",
        "init = TF.to_tensor(init).to(device).unsqueeze(0).clamp(0,1)\n",
        "h = ldm.encode(init * 2 - 1) *  0.18215\n",
        "init = torch.cat(1*2*[h], dim=0)\n",
        "'''\n",
        "init=None\n",
        "\n",
        "for i in range(1):\n",
        "    cur_t = diffusion.num_timesteps - 1\n",
        "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "      samples = sample_fn(\n",
        "          model_fn,\n",
        "          (batchsz*2, 4, height>>3, width>>3),\n",
        "          clip_denoised=False,\n",
        "          model_kwargs=kwargs,\n",
        "          cond_fn=None,\n",
        "          device=device,\n",
        "          progress=True,\n",
        "          init_image=init,\n",
        "          skip_timesteps=0,\n",
        "      )\n",
        "\n",
        "    for j, sample in enumerate(samples):\n",
        "        cur_t -= 1\n",
        "\n",
        "    save_sample(i, sample)\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "62dodU08IN9i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}